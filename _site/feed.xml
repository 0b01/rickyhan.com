<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ricky Han blog</title>
    <description>Programming demos, tips, thoughts.
</description>
    <link>http://rickyhan.com/</link>
    <atom:link href="http://rickyhan.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 17 Mar 2018 23:06:24 -0400</pubDate>
    <lastBuildDate>Sat, 17 Mar 2018 23:06:24 -0400</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>Why We Need Type-Checked Neural Network</title>
        <description>&lt;p&gt;Imagine a framework-agnostic DSL with strong typing, dimension and ownership checking and lots of syntax sugar. What would it be like? As interesting as it is, here is why there needs to a langauge for neural network:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Multi-target. Write once, run everywhere(interpreted or compiled).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Typechecking with good type annotation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Parallellize with language-level directives&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Composition(constructing larger systems with building blocks) is easier&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ownership system because GC in CUDA is a nightmare&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;No more frustration from deciphering undocumented code written by researchers. The issue is, an overwhelming majority of researchers are not programmers, who care about the aesthetics of clean code and helpful documentation. I get it - people are lazy and unsafe unless the compiler forces them to annotate their code.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have thought a lot about this. Here is an example snippet of the language I have in mind:&lt;/p&gt;

&lt;p&gt;```rust
use conv::{Conv2d, Dropout2d, maxpool2d};
use loss::log_softmax;
use nonlin::relu;
use lin::Linear;&lt;/p&gt;

&lt;p&gt;node Mnist&amp;lt;?,c,h,w -&amp;gt; ?,10&amp;gt;;&lt;/p&gt;

&lt;p&gt;weights Mnist {
    conv1: Conv2d&amp;lt;?,c,hi,wi -&amp;gt; ?,c,ho,wo&amp;gt;::new(in_ch=1, out_ch=10, kernel_size=5),
    conv2: Conv2d&amp;lt;?,c,hi,wi -&amp;gt; ?,c,ho,wo&amp;gt;::new(in_ch=10, out_ch=20, kernel_size=5),
    dropout: Dropout2d&amp;lt;?,c,h,w -&amp;gt; ?,c,h,w&amp;gt;::new(p=0.5),
    fc1: Linear&amp;lt;?,320 -&amp;gt; ?,50&amp;gt;::new(),
    fc2: Linear&amp;lt;?,50 -&amp;gt; ?,10&amp;gt;::new(),
}&lt;/p&gt;

&lt;p&gt;graph Mnist {
    fn new() {
        fc1.init_normal(std=1.);
        fc2.init_normal(std=1.);
    }&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fn forward(self, x) {
    x
    |&amp;gt; conv1            |&amp;gt; maxpool2d(kernel_size=2)
    |&amp;gt; conv2 |&amp;gt; dropout |&amp;gt; maxpool2d(kernel_size=2)
    |&amp;gt; view(?, 320)
    |&amp;gt; fc1 |&amp;gt; relu
    |&amp;gt; self.fc2()
    |&amp;gt; log_softmax(dim=1)
}

fn fc2(self, x: &amp;lt;?,50&amp;gt;) -&amp;gt; &amp;lt;?,10&amp;gt;{
    x |&amp;gt; fc2 |&amp;gt; relu
} } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, this is inspired by Rust, PyTorch, Elixir.&lt;/p&gt;

&lt;p&gt;Here are some random syntactical ideas:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Stateful symbols are capitalized&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Impure functions must be annonated&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Local variables cannot be shadowed&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Function args have keyword&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Be explicit where you can&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pipe operator input is first argument of function&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;However, this will be an extraordinary undertaking &lt;em&gt;IF&lt;/em&gt; I decide to implement it.&lt;/p&gt;
</description>
        <pubDate>Thu, 15 Feb 2018 23:00:00 -0500</pubDate>
        <link>http://rickyhan.com/jekyll/update/2018/02/15/tensorscript.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2018/02/15/tensorscript.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Tensorflow FizzBuzz Revisited</title>
        <description>&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: Welcome. You file indicates an application from two years ago but &lt;a href=&quot;http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/&quot;&gt;didn’t pass the coding interview&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: Yes. I had some trouble with FizzBuzz.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: FizzBuzz? That seems too easy for your credentials.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: Unfortunately, the whiteboard didn’t have a GPU.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: Well. Don’t stress about it. Many of our top performers interviewed multiple times.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: I am confident, now that I have two more years of experience.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: I like your spirit. Let’s get started. Since you mentioned it, do a FizzBuzz in the language of your choice.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: Can you repeat the requirement just so we are on the same page?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: Sure. Print from 1 to 100, except when n is divisible by 3 print “fizz”, by 5 print “buzz”, and if it’s divisible by 15 print “fizzbuzz”.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: Very well.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;ruminates and writes down&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
length = 100
arr = [&#39;&#39;] * (length-1)
i = 1
while i &amp;lt; length:
    if n % 3 == 0 and n % 5 == 0:
        arr[n-1] = &#39;FizzBuzz&#39;
    elif n % 3 == 0:
        arr[n-1] = &#39;Fizz&#39;
    elif n % 5 == 0:
        arr[n-1] = &#39;Buzz&#39;
    else:
        arr
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: Your code is almost correct. Do you see what’s wrong?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: I know what you are thinking. This is only one piece of the puzzle.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: &lt;em&gt;*confused*&lt;/em&gt; Could you explain your strategy?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: I am going to run it in TensorFlow. Now I just need to transform the abstract syntax tree.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: You got it but you are overthinking it. Well, we can move on to systems design questions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;me&lt;/strong&gt;: It doesn’t very long. Let me explain:&lt;/p&gt;

&lt;p&gt;Tensorflow specializes in Machine Learning but its internal graph data structure is suitable for general dataflow programming. Now my subgoal is: write some AST transforms to transpile regular python into TensorFlow function calls. For example, python loops into &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.while_loop&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;```python
import astunparse, ast, astpretty
from ast import *&lt;/p&gt;

&lt;p&gt;fname = “./raw_fizzbuzz.py”
with open(fname) as f:
    txt = f.read()
myast = ast.parse(txt)&lt;/p&gt;

&lt;h1 id=&quot;transform&quot;&gt;transform&lt;/h1&gt;

&lt;p&gt;print(astunparse.unparse(myast))
```&lt;/p&gt;

&lt;p&gt;Python has a built-in package called &lt;a href=&quot;https://docs.python.org/2/library/ast.html&quot;&gt;ast&lt;/a&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;NodeTransformer&lt;/code&gt; provides handy tree modifications. Allow me to demonstrate.&lt;/p&gt;

&lt;p&gt;```python
class RewriteName(NodeTransformer):
    def visit_BoolOp(self, node):
        # print astpretty.pprint(node)
        if isinstance(node.op, And):
            funcname = “tf.logical_and”
            return copy_location(Call(
                func=Name(id=funcname, ctx=Load()),
                args=(
                    self.visit(node.values[0]),
                    self.visit(node.values[1])
                    ),
                keywords=(),
                starargs=(),
                kwargs=(),
            ), node)
        # omitted …
        else:
            return node&lt;/p&gt;

&lt;p&gt;myast = RewriteName().visit(myast)
```&lt;/p&gt;

&lt;p&gt;This function visits all &lt;code class=&quot;highlighter-rouge&quot;&gt;BoolOp&lt;/code&gt; nodes and replaces &lt;code class=&quot;highlighter-rouge&quot;&gt;==&lt;/code&gt; operator with corresponding &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.logical_and&lt;/code&gt; function call.&lt;/p&gt;

&lt;p&gt;I won’t include all the transforms. If anyone at your company has to write a lot of tensorflow-ism(which is rare), I have posted it &lt;a href=&quot;https://gist.github.com/rickyhan/eea717ee5de492e52b84d3bea357e40e&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The result(after some manual cleanup):&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
import tensorflow as tf
length = 100
arr = tf.Variable([str(i) for i in range(1, length+1)])
graph = tf.while_loop(
    (lambda i, _: tf.less(i, length+1)), 
    (lambda i, _: (tf.add(i,1), tf.cond(
        tf.logical_and(tf.equal(tf.mod(i, 3), 0), tf.equal(tf.mod(i, 5), 0)),
        (lambda : tf.assign(arr[(i - 1)], &#39;FizzBuzz&#39;)),
        (lambda : tf.cond(tf.equal(tf.mod(i, 3), 0),
            (lambda : tf.assign(arr[(i - 1)], &#39;Fizz&#39;)),
            (lambda : tf.cond(tf.equal(tf.mod(i, 5), 0),
                (lambda : tf.assign(arr[(i - 1)], &#39;Buzz&#39;)),
                (lambda : arr)))))))),
    [1, arr])
with tf.Session() as sess:
    tf.global_variables_initializer().run()
    idx, array = sess.run(graph)
    print array
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Since TensorFlow has &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.cond&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.while_loop&lt;/code&gt;, it is Turing complete like a lot of programming languages. FizzBuzz, quicksort, Dijkstra’s algorithm all can be implemented in Tensorflow.&lt;/p&gt;

&lt;p&gt;And here is the result:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
g@g:~/Desktop/py2tf⟫ python test.py 
2018-02-17 00:31:12.564103: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-17 00:31:12.564124: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-17 00:31:12.564128: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-17 00:31:12.564132: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-17 00:31:12.564135: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[&#39;1&#39; &#39;2&#39; &#39;Fizz&#39; &#39;4&#39; &#39;Buzz&#39; &#39;Fizz&#39; &#39;7&#39; &#39;8&#39; &#39;Fizz&#39; &#39;Buzz&#39; &#39;11&#39; &#39;Fizz&#39; &#39;13&#39;
 &#39;14&#39; &#39;FizzBuzz&#39; &#39;16&#39; &#39;17&#39; &#39;Fizz&#39; &#39;19&#39; &#39;Buzz&#39; &#39;Fizz&#39; &#39;22&#39; &#39;23&#39; &#39;Fizz&#39;
 &#39;Buzz&#39; &#39;26&#39; &#39;Fizz&#39; &#39;28&#39; &#39;29&#39; &#39;FizzBuzz&#39; &#39;31&#39; &#39;32&#39; &#39;Fizz&#39; &#39;34&#39; &#39;Buzz&#39;
 &#39;Fizz&#39; &#39;37&#39; &#39;38&#39; &#39;Fizz&#39; &#39;Buzz&#39; &#39;41&#39; &#39;Fizz&#39; &#39;43&#39; &#39;44&#39; &#39;FizzBuzz&#39; &#39;46&#39; &#39;47&#39;
 &#39;Fizz&#39; &#39;49&#39; &#39;Buzz&#39; &#39;Fizz&#39; &#39;52&#39; &#39;53&#39; &#39;Fizz&#39; &#39;Buzz&#39; &#39;56&#39; &#39;Fizz&#39; &#39;58&#39; &#39;59&#39;
 &#39;FizzBuzz&#39; &#39;61&#39; &#39;62&#39; &#39;Fizz&#39; &#39;64&#39; &#39;Buzz&#39; &#39;Fizz&#39; &#39;67&#39; &#39;68&#39; &#39;Fizz&#39; &#39;Buzz&#39;
 &#39;71&#39; &#39;Fizz&#39; &#39;73&#39; &#39;74&#39; &#39;FizzBuzz&#39; &#39;76&#39; &#39;77&#39; &#39;Fizz&#39; &#39;79&#39; &#39;Buzz&#39; &#39;Fizz&#39; &#39;82&#39;
 &#39;83&#39; &#39;Fizz&#39; &#39;Buzz&#39; &#39;86&#39; &#39;Fizz&#39; &#39;88&#39; &#39;89&#39; &#39;FizzBuzz&#39; &#39;91&#39; &#39;92&#39; &#39;Fizz&#39; &#39;94&#39;
 &#39;Buzz&#39; &#39;Fizz&#39; &#39;97&#39; &#39;98&#39; &#39;Fizz&#39; &#39;Buzz&#39;]
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interviewer&lt;/strong&gt;: Don’t apply again.&lt;/p&gt;

&lt;p&gt;Read &lt;a href=&quot;http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/&quot;&gt;the OG fizzbuzzer&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 15 Feb 2018 23:00:00 -0500</pubDate>
        <link>http://rickyhan.com/jekyll/update/2018/02/15/tensorflow-fizzbuzz-revisited.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2018/02/15/tensorflow-fizzbuzz-revisited.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Guitar Effects in Rust</title>
        <description>&lt;p&gt;A guitar effect alters how the input sounds by adding distortion, delaying signal, shifting pitch/frequency and changing dynamics and loudness. Most physical pedals are analog - altering the electric signals directly, with non-existent latency. Digital effect units sample the source input at high frequencies(44100 Hertz) and quickly process using DSP algorithms so the output appears live.&lt;/p&gt;

&lt;p&gt;This projects uses JACK(&lt;strong&gt;J&lt;/strong&gt;ACK &lt;strong&gt;A&lt;/strong&gt;udio &lt;strong&gt;C&lt;/strong&gt;onnection &lt;strong&gt;K&lt;/strong&gt;it), registers input and output ports on JACK server. I googled around and found &lt;a href=&quot;https://github.com/RustAudio/rust-jack&quot;&gt;rust-jack&lt;/a&gt; and quickly got audio playback to work.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/out.mp3&quot;&gt;Sample mp3&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;/h1&gt;

&lt;p&gt;I first booted up a server with &lt;a href=&quot;https://i.imgur.com/7052cHF.png&quot;&gt;qjackctl&lt;/a&gt;, then got a playback example to work:&lt;/p&gt;

&lt;p&gt;```rust
extern crate jack;
use std::io;&lt;/p&gt;

&lt;p&gt;fn main() {
    let (client, _status) =
        jack::Client::new(“rasta”, jack::ClientOptions::NO_START_SERVER).unwrap();&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// register ports
let in_b = client
    .register_port(&quot;guitar_in&quot;, jack::AudioIn::default())
    .unwrap();
let mut out_a = client
    .register_port(&quot;rasta_out_l&quot;, jack::AudioOut::default())
    .unwrap();
let mut out_b = client
    .register_port(&quot;rasta_out_r&quot;, jack::AudioOut::default())
    .unwrap();

let process_callback = move |_: &amp;amp;jack::Client, ps: &amp;amp;jack::ProcessScope| -&amp;gt; jack::Control {
    let out_a_p = out_a.as_mut_slice(ps);
    let out_b_p = out_b.as_mut_slice(ps);
    let in_b_p = in_b.as_slice(ps);
    out_a_p.clone_from_slice(&amp;amp;in_b_p);
    out_b_p.clone_from_slice(&amp;amp;in_b_p);
    jack::Control::Continue
};
let process = jack::ClosureProcessHandler::new(process_callback);
let active_client = client.activate_async((), process).unwrap();

// Wait for user input to quit
println!(&quot;Press enter/return to quit...&quot;);
let mut user_input = String::new();
io::stdin().read_line(&amp;amp;mut user_input).ok();

active_client.deactivate().unwrap(); } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This program copies a &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;amp;[f32]&lt;/code&gt; of length &lt;code class=&quot;highlighter-rouge&quot;&gt;samples/period&lt;/code&gt;(in this case 128) from input port to output port for 44100 times every second.&lt;/p&gt;

&lt;p&gt;Now it’s time to implement some cool effects! But first, let’s create a trait to keep things organized.&lt;/p&gt;

&lt;h1 id=&quot;effect-trait&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Effect&lt;/code&gt; trait&lt;/h1&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rust
pub trait Effect : Send {
    fn new() -&amp;gt; Self
        where Self: Sized;
    fn name(&amp;amp;self) -&amp;gt; &amp;amp;&#39;static str;
    fn process_samples(&amp;amp;self, input: &amp;amp;[f32], output_l: &amp;amp;mut [f32], output_r: &amp;amp;mut [f32]) {
        output_l.clone_from_slice(input);
        output_r.clone_from_slice(input);
    }
    fn bypass(&amp;amp;mut self);
    fn ctrl(&amp;amp;mut self, msg: CtrlMsg);
}
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This trait defines the minimum set of methods for an effect struct. Note that Effect needs to be &lt;code class=&quot;highlighter-rouge&quot;&gt;Send&lt;/code&gt; for it to cross thread boundaries(for example, move into the closure) and &lt;code class=&quot;highlighter-rouge&quot;&gt;Sized&lt;/code&gt; for it to be a &lt;a href=&quot;https://doc.rust-lang.org/book/first-edition/trait-objects.html#object-safety&quot;&gt;trait object&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;overdrive&quot;&gt;Overdrive&lt;/h1&gt;

&lt;p&gt;Then I wrote a very simple but real effect: overdrive. Guitarists originally obtained an overdriven sound by turning up their vacuum tube-powered guitar amplifiers to high volumes, which caused the signal to get distorted(wiki).&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rust
use effects::{Effect, CtrlMsg};
pub struct Overdrive {
    pub bypassing: bool,
}
impl Effect for Overdrive {
    fn new() -&amp;gt; Self {
        Overdrive {
            bypassing: false
        }
    }
    fn name(&amp;amp;self) -&amp;gt; &amp;amp;&#39;static str {
        &quot;overdrive&quot;
    }
    fn process_samples(&amp;amp;mut self, input: &amp;amp;[f32], output_l: &amp;amp;mut [f32], output_r: &amp;amp;mut [f32]) {
        if self.bypassing { return; }
        for (i, x) in input.iter().enumerate() {
            let x = x.abs();
            let y = if 0. &amp;lt; x  &amp;amp;&amp;amp; x &amp;lt; 0.333 {
                2. * x
            } else if 0.333 &amp;lt; x &amp;amp;&amp;amp; x &amp;lt; 0.666 {
                let t = 2. - 3. * x;
                (3. - t * t) / 3.
            } else {
                x
            };
            output_l[i] = y;
            output_r[i] = y;
        }
    }
    fn bypass(&amp;amp;mut self) {
        self.bypassing = !self.bypassing;
    }
    fn ctrl(&amp;amp;mut self, msg: CtrlMsg) {
        use self::CtrlMsg::*;
        match msg {
            Bypass =&amp;gt; self.bypass(),
        }
    }
}
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This effect doubles quiet signals such as eddy currents produced by pickup. It uses a &lt;a href=&quot;http://sound.whsites.net/articles/soft-clip.htm&quot;&gt;symmetrical soft clipping&lt;/a&gt; to amplify the middle parts. It sounds exactly like the overdrive on my amp.&lt;/p&gt;

&lt;h1 id=&quot;delay&quot;&gt;Delay&lt;/h1&gt;

&lt;p&gt;After writing overdrive, I wanted to implement a time-dependent effect. Some sort of delay, echo, reverb would be nice. A delay of 0.2 second with 0.3 feedback means an attenuated echo of amplitude 0.3 of the original after 0.2 seconds, and then another echo of amplitude of 0.09 after 0.4 seconds.&lt;/p&gt;

&lt;p&gt;This can be done in 2 ways:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Convolve the original signal with an impulse response. See this excellent &lt;a href=&quot;https://youtu.be/HTfa2UF_oiI?t=27m53s&quot;&gt;talk&lt;/a&gt;. However, this is out of scope for our purpose.&lt;/li&gt;
  &lt;li&gt;Use a longer buffer to store previous signals and calcuate an attenuated signal from t samples before. A good data structure to use for this is the &lt;strong&gt;ring buffer&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is the implementation for this effect(explanation below):&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rust
for bufidx in 0..self.frame_size as usize {
    if self.writer_idx &amp;gt;= self.delay_buffer_size {
        self.writer_idx = 0;
    }
    self.reader_idx = if self.writer_idx &amp;gt;= self.delay_time {
        self.writer_idx - self.delay_time
    } else {
        self.delay_buffer_size as usize + self.writer_idx - self.delay_time
    };
    let processed = input[bufidx] + (self.delay_buffer[self.reader_idx] * self.feedback);
    self.delay_buffer[self.writer_idx] = processed;
    let out = (processed + 0.5).cos();
    output_r[bufidx] = out;
    output_l[bufidx] = out;
    self.writer_idx += 1;
}
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This effect uses a ring buffer which is a fixed sized vector for streaming data. It overwrites data in the front when a pointer reaches the end. A notable property of the ring buffer is that it’s locklessly thread safe as long as there is only one reader and one writer whose roles aren’t switched, and writer pointer never catches up with reader pointer. The difference between writer and reader pointers is always the delayed samples. The rest is trivial.&lt;/p&gt;

&lt;h1 id=&quot;auto-wah&quot;&gt;Auto Wah&lt;/h1&gt;

&lt;p&gt;Auto Wah is my personal favorite(vocoder after). The idea is simple: autowah ≡ filter controlled by envelope follower. The louder the sound, the more oo, and conversely aa. The filter can be tweaked to output different human sounding vowel voices like ooii(highpass filter), ooaa(bandpass), ooee(lowpass). Unlike a conventional wah pedal, it only responds to the volume of the input signal - buffer not needed. The code below is ported from a C++ implementation found on &lt;a href=&quot;https://github.com/dangpzanco/autowah&quot;&gt;github&lt;/a&gt;. All credit goes to the original author.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/tWrOwXs.png&quot; alt=&quot;image courtesy of the original author&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The implementation is omitted, if you are interested go to the repo.&lt;/p&gt;

&lt;p&gt;The filter outputs oo and aa, which is then mixed back into the original signal. All of these parameters can be tweaked just like on a real physical pedal.&lt;/p&gt;

&lt;h1 id=&quot;tuner&quot;&gt;Tuner&lt;/h1&gt;

&lt;p&gt;What good is an effect processor if it doesn’t have a tuner? Admittedly, I never use these but wrote one for the sake of completeness. This is very straightforward Fourier transform based pitch detector. It converts the signals from time domain into frequency domain and finds the maximum frequency. Originally, the input of the transform was the 128 signals and it took me a while to realize that would only output 64 distinct discrete frequencies which are way too few. The resulting count is half because of symmetry of cos(t) = e^(it) + e^(-it). So I created a buffer but then found out it took way too long (30ms). Finally, I moved the tuner to run in a separate thread so it doesn’t block.&lt;/p&gt;

&lt;p&gt;```rust
static TUNER_BUFFER_SIZE : usize = 10240;&lt;/p&gt;

&lt;p&gt;use std::time::Instant;
use std::thread;&lt;/p&gt;

&lt;p&gt;extern crate rustfft;
use effects::{CtrlMsg, Effect};
use self::rustfft::FFTplanner;
use self::rustfft::num_complex::Complex;
use self::rustfft::num_traits::Zero;&lt;/p&gt;

&lt;p&gt;pub fn calculate_spectrum(samples: &amp;amp;[f32]) -&amp;gt; Vec&lt;f32&gt; {
    let now = Instant::now();&lt;/f32&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let mut input: Vec&amp;lt;Complex&amp;lt;f32&amp;gt;&amp;gt; = samples.iter()
    .map(|&amp;amp;x| Complex::new(x, 0.0))
    .collect();

let mut output: Vec&amp;lt;Complex&amp;lt;f32&amp;gt;&amp;gt; = vec![Complex::zero(); input.len()];

let mut planner = FFTplanner::new(false);
let fft = planner.plan_fft(input.len());
fft.process(&amp;amp;mut input, &amp;amp;mut output);

println!(&quot;{:?}&quot;, now.elapsed());

output.iter()
    .map(|&amp;amp;c| c.norm_sqr())
    .collect() }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;pub fn tune(input: &amp;amp;[f32], sample_rate: usize) -&amp;gt; Option&lt;f32&gt; {&lt;/f32&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let input_len = input.len();
let freqs = calculate_spectrum(input);

let buckets: Vec&amp;lt;_&amp;gt; =
    (0 .. 1 + input_len / 2) // has Hermitian symmetry to f=0
    .filter_map(|i| {
        let norm = freqs[i];
        let noise_threshold = 1.0;
        if norm &amp;gt; noise_threshold {
            let f = i as f32 / input_len as f32 * sample_rate as f32;
            Some((f, norm))
        } else {
            None
        }
    })
    .collect();

if buckets.is_empty() {
    return None
}

let &amp;amp;(max_f, _max_val) =
    buckets.iter()
    .max_by(|&amp;amp;&amp;amp;(_f1, ref val1), &amp;amp;&amp;amp;(_f2, ref val2)| val1.partial_cmp(val2).unwrap())
    .unwrap();
println!(&quot;Freq is {}&quot;, max_f);
Some(max_f) }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;h1 id=&quot;putting-everything-together&quot;&gt;Putting everything together&lt;/h1&gt;

&lt;p&gt;Finally, I want to chain several effects together, change connections, tweak parameters on the fly. To do this, I store the connections in a graph. And based on the graph definition dynamically dispatch computation by looking up from a hashmap of &lt;code class=&quot;highlighter-rouge&quot;&gt;Box&amp;lt;Effect&amp;gt;&lt;/code&gt;. I also wrote a little command parser to do things like &lt;code class=&quot;highlighter-rouge&quot;&gt;c in tuner autowah delay out&lt;/code&gt; which daisy chains everything from in to out. At this point, I was pretty bored, ready to liquidate my learns and forget about this weekend hack.&lt;/p&gt;

&lt;h1 id=&quot;more&quot;&gt;More&lt;/h1&gt;

&lt;p&gt;I would love to add vocoder which applies pitch shift to mic input based on guitar notes.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In an effort to experiment with dsp, I wrote a guitar/bass effects processor this past weekend. The end result works very well(to my pleasant surprise). It doesn’t have 90% of the functionalities of any of rakarrack, guitar rig, garage band but overall it was a fun weekend hack.&lt;/p&gt;

&lt;h1 id=&quot;if-you-find-this-article-helpful-you-should-sign-up-to-get-updateshttpstinylettercomrickyhan&quot;&gt;&lt;a href=&quot;https://tinyletter.com/rickyhan&quot;&gt;If you find this article helpful, you should sign up to get updates.&lt;/a&gt;&lt;/h1&gt;
</description>
        <pubDate>Mon, 05 Feb 2018 23:00:00 -0500</pubDate>
        <link>http://rickyhan.com/jekyll/update/2018/02/05/rust-guitar-pedal-effects-dsp.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2018/02/05/rust-guitar-pedal-effects-dsp.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>How to use async generator in python3.6 to process streaming data</title>
        <description>&lt;p&gt;Like many, my first programming language is Python 2.7. This year, I decided to make the switch &lt;code class=&quot;highlighter-rouge&quot;&gt;alias python=python3.6&lt;/code&gt;. Other than a 10% increase in processing speed, it has some perks not previously possible in 2.7.&lt;/p&gt;

&lt;p&gt;In this post, I will publish a minimal, complete, and verifiable example of a script implemented in Python 3.6.&lt;/p&gt;

&lt;h2 id=&quot;async-generators-what-are-those&quot;&gt;Async Generators: what are those?&lt;/h2&gt;

&lt;p&gt;Suppose we have a stream that generates a bunch of values required by other parts of the program. With &lt;code class=&quot;highlighter-rouge&quot;&gt;asyncio&lt;/code&gt;, the stream processing loop is run concurrently so it doesn’t block. It is introduced in 3.6.&lt;/p&gt;

&lt;p&gt;This example program does the following:
1. Receive a batch of data from stream continuously
2. Every x seconds, do something with the batch, repeat&lt;/p&gt;

&lt;p&gt;Here is the async generator:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
import asyncio
from tectonic import TectonicDB
import json
async def subscribe(name):
    db = TectonicDB(host=&quot;localhost&quot;, port=9001)
    _success, _text = await db.subscribe(name)
    while 1:
        _, text = await db.poll()
        if b&quot;NONE&quot; == text:
            await asyncio.sleep(0.001)
        else:
            yield json.loads(text)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As we can see, &lt;code class=&quot;highlighter-rouge&quot;&gt;subscribe&lt;/code&gt; connects to a TectonicDB instance and subscribes to a data store then polls forever. This coroutine yields new order book updates as they come in.&lt;/p&gt;

&lt;p&gt;Next, we define a structure to store this data.&lt;/p&gt;

&lt;p&gt;```python
class TickBatcher(object):
    def &lt;strong&gt;init&lt;/strong&gt;(self, db_name):
        self.one_batch = []
        self.db_name = db_name&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;async def sub(self):
    async for item in subscribe(self.db_name):
        self.one_batch.append(item) ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now since the generator is async, the iteration must also be async as in only iterate when new data comes in.&lt;/p&gt;

&lt;p&gt;We write the main logic in a separate coroutine.&lt;/p&gt;

&lt;p&gt;```python
def timer(secs=1):
    “&quot;”async timer decorator”””
    def _timer(f):
        async def wrapper(*args, **kwargs):
            while 1:
                await asyncio.sleep(s)
                await f()
        return wrapper
    return _timer&lt;/p&gt;

&lt;p&gt;class TickBatcher(object):
    …
    @timer(secs=10)
    async def run(self):
        # do work here
        print(len(self.one_batch))
        self.one_batch = []
```&lt;/p&gt;

&lt;p&gt;We use a decorator to hide the &lt;code class=&quot;highlighter-rouge&quot;&gt;sleep&lt;/code&gt;ing logic.&lt;/p&gt;

&lt;p&gt;Finally, in order to run the program, we need to create the tasks separately.&lt;/p&gt;

&lt;p&gt;```python
if &lt;strong&gt;name&lt;/strong&gt; == ‘&lt;strong&gt;main&lt;/strong&gt;’:
    loop = asyncio.get_event_loop()&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;proc = TickBatcher(&quot;bnc_xrp_btc&quot;)
loop.create_task(proc.sub())
loop.create_task(proc.run())

loop.run_forever()
loop.close() ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this short post we used Python3.6 async generator to implement a simple script to monitor market or place simple orders.&lt;/p&gt;

&lt;h1 id=&quot;if-you-find-this-article-helpful-you-should-sign-up-to-get-updateshttpstinylettercomrickyhan&quot;&gt;&lt;a href=&quot;https://tinyletter.com/rickyhan&quot;&gt;If you find this article helpful, you should sign up to get updates.&lt;/a&gt;&lt;/h1&gt;
</description>
        <pubDate>Fri, 26 Jan 2018 23:00:00 -0500</pubDate>
        <link>http://rickyhan.com/jekyll/update/2018/01/26/python36.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2018/01/26/python36.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Gradient Trader Part 4: Build Training Set with Rust for Python</title>
        <description>&lt;p&gt;Preparing dataset for machine learning is a CPU heavy task. To optimize for GPU utilization during training, it is imperative to process the data before training. What is the proper way to approach this? Depends on how much data you have.&lt;/p&gt;

&lt;p&gt;Recently, I trained a new model. I had 60GB &lt;a href=&quot;http://rickyhan.com/jekyll/update/2017/10/27/how-to-handle-order-book-data.html&quot;&gt;compressed&lt;/a&gt; order book data with which I needed to generate a 680GB training set.&lt;/p&gt;

&lt;p&gt;This post is about the awkward situation where the dataset is not big enough to warrant Spark but would take too long to run on your computer. A top-end deep learning box only has a maximum of 32 cores while AWS has 128 cores on demand for $13.388/hr. A simple back-of-the-envelop calculation shows that if a task takes 24 hours on an Intel i7 with 8 threads, or &lt;code class=&quot;highlighter-rouge&quot;&gt;24 * 8 (hour x thread)&lt;/code&gt; then it would only take ~1 hour to run on a 128 core instance for the price of a burrito. Another pro is the huge memory(1952GB) that should fit most datasets.&lt;/p&gt;

&lt;p&gt;I use Rust to do the heavy lifting and in this post I will cover these two aspects:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Using multiple cores&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Saving to Numpy format&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;parallel-programming&quot;&gt;Parallel Programming&lt;/h1&gt;

&lt;p&gt;I suck at writing parallel code. About 4 months ago, I wrote this monstrocity. Feel free to skip it.&lt;/p&gt;

&lt;p&gt;```python
import multiprocessing
import tensorflow as tf
from functools import partial
import gc&lt;/p&gt;

&lt;p&gt;def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))&lt;/p&gt;

&lt;p&gt;batch_size = 256
time_steps = 256
max_scale = max(SCALES)
min_padding = max_scale * time_steps
maximum_sequential_epoch_sequence = range(get_min_epoch(), get_max_epoch(), 60)
ok_epochs = set(maximum_sequential_epoch_sequence[min_padding:-min_padding])
# ok_epochs = set(list(ok_epochs)[:len(ok_epochs)/8])
# ok_epochs = set(list(ok_epochs)[len(ok_epochs)/8   : len(ok_epochs)/8&lt;em&gt;2])
# ok_epochs = set(list(ok_epochs)[len(ok_epochs)/8&lt;/em&gt;2 : len(ok_epochs)/8&lt;em&gt;3])
# ok_epochs = set(list(ok_epochs)[len(ok_epochs)/8&lt;/em&gt;3 : len(ok_epochs)/8*4])&lt;/p&gt;

&lt;h1 id=&quot;okepochs--setlistokepochslenokepochs84--lenokepochs85&quot;&gt;ok_epochs = set(list(ok_epochs)[len(ok_epochs)/8&lt;em&gt;4 : len(ok_epochs)/8&lt;/em&gt;5])&lt;/h1&gt;
&lt;p&gt;# ok_epochs = set(list(ok_epochs)[len(ok_epochs)/8&lt;em&gt;5 : len(ok_epochs)/8&lt;/em&gt;6])
# ok_epochs = set(list(ok_epochs)[len(ok_epochs)/8&lt;em&gt;6 : len(ok_epochs)/8&lt;/em&gt;7])
# ok_epochs = set(list(ok_epochs)[len(ok_epochs)/8*7 : ])&lt;/p&gt;

&lt;p&gt;def gen_all_the_tf_records(n, myepochs):
    tfrecords_filename = ‘/home/ubuntu/tfrecords/5/{}.tfrecords’.format(n)
    writer = tf.python_io.TFRecordWriter(tfrecords_filename)
    for random_epochs in tqdm(myepochs):
        features = [redacted]
        minibatch = np.stack(features, axis=0)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    example = tf.train.Example(features=tf.train.Features(feature={
        &#39;minibatch&#39;: _bytes_feature(minibatch.tostring())
    }))
    writer.write(example.SerializeToString())
    gc.collect()
writer.close()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;def tfrecords_cli():
    global ok_epochs
    iterable = range(len(ok_epochs) / batch_size)
    arrs = []
    threads = 35
    for _ in range(threads):
        arrs.append([])&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for i, _ in tqdm(enumerate(iterable)):
    for arr_i in range(threads):
        if batch_size &amp;gt; len(ok_epochs):
            break
        rand = random.sample(ok_epochs, batch_size)
        arrs[arr_i].append(rand)
        ok_epochs -= set(rand)
gc.collect()
ps = []
for i in range(threads):
    p = multiprocessing.Process(
        target=gen_all_the_tf_records, args=(i, arrs[i]))
    ps.append(p)
for i, p in enumerate(ps):
    print i , &quot;started&quot;
    p.start() ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Notice how the &lt;code class=&quot;highlighter-rouge&quot;&gt;ok_epochs&lt;/code&gt; are changed during every run because it just wouldn’t fit into memory. This piece of crap worked and I don’t want to talk about it.&lt;/p&gt;

&lt;p&gt;Compare it to Rayon, parallelization requires virtually no change. This example is taken from &lt;a href=&quot;http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rust
// sequential
let total_price = stores.iter()
                        .map(|store| store.compute_price(&amp;amp;list))
                        .sum();
// parallel
let total_price = stores.into_par_iter()
                        .map(|store| store.compute_price(&amp;amp;list))
                        .sum();
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;When I tested Rayon on my laptop, it &lt;em&gt;really&lt;/em&gt; was 4x as fast. This is about as easy it gets when it comes to multi-core programming.&lt;/p&gt;

&lt;h1 id=&quot;using-numpy-format&quot;&gt;Using Numpy format&lt;/h1&gt;

&lt;p&gt;I save minibatches in &lt;a href=&quot;https://docs.scipy.org/doc/numpy-1.13.0/neps/npy-format.html&quot;&gt;numpy binary format&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To restore a numpy array from disk:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
import numpy as np
minibatch = np.load(&quot;minibatch.npy&quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Again, minimal coding required and no tfrecords involved.&lt;/p&gt;

&lt;p&gt;Since I’m dealing with spatial-temporal data(for RNN), I need to generate feature tensor of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;[batch_size, time_step, input_dim]&lt;/code&gt;. To do this, I wrote a serializer for the &lt;code class=&quot;highlighter-rouge&quot;&gt;npy&lt;/code&gt; format.&lt;/p&gt;

&lt;p&gt;```rust
// write_npy.rs
use byteorder::{BE, LE, WriteBytesExt};
use std::io::Write;&lt;/p&gt;

&lt;p&gt;use record::*;&lt;/p&gt;

&lt;p&gt;static MAGIC_VALUE : &amp;amp;[u8] = &amp;amp;[0x93, 0x4E, 0x55, 0x4D, 0x50, 0x59];&lt;/p&gt;

&lt;p&gt;fn get_header() -&amp;gt; String {
    format!(“
      {{‘descr’: [(‘data’, ‘&amp;gt;f4’)],’fortran_order’: False,’shape’: ({},{},{})}}”,
        BATCH_SIZE, TIME_STEP, INPUT_DIM)
}&lt;/p&gt;

&lt;p&gt;/// these are just from the spec
pub fn write(wtr: &amp;amp;mut Write, record: &amp;amp;Record) {
    let _ = wtr.write(MAGIC_VALUE);
    let _ = wtr.write_u8(0x01); // major version
    let _ = wtr.write_u8(0x00); // minor version
    let header = &amp;amp;get_header();
    let header_len = header.len();
    let _ = wtr.write_u16::&lt;le&gt;(header_len as u16);
    let _ = wtr.write(header.as_bytes()); // header&lt;/le&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for batch in record.iter() {
    for step in batch.iter() {
        for input in step.iter() {
            let _ = wtr.write_f32::&amp;lt;BE&amp;gt;(*input);
        }
    }
} } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;```rust
// record.rs
pub const INPUT_DIM: usize = 6;
pub const TIME_STEP: usize = 5;
pub const BATCH_SIZE: usize = 4;&lt;/p&gt;

&lt;p&gt;// shape [batch_size, time_step, input_dim]
pub type Record = [[[ f32 ; INPUT_DIM]; TIME_STEP]; BATCH_SIZE];
```&lt;/p&gt;

&lt;p&gt;```rust
// main.rs&lt;/p&gt;

&lt;p&gt;extern crate byteorder;
mod write_npy;
mod record;&lt;/p&gt;

&lt;p&gt;use record::*;
use std::io::BufWriter;
use std::fs::File;&lt;/p&gt;

&lt;p&gt;fn main() {
    let fname = “minibatch.npy”;
    let new_file = File::create(fname).unwrap();
    let mut wtr = BufWriter::new(new_file);&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let mut record = [[[ 0_f32 ; INPUT_DIM]; TIME_STEP]; BATCH_SIZE];
for batch in 0..BATCH_SIZE {
    for step in 0..TIME_STEP {
        for dim in 0..INPUT_DIM {
            record[batch][step][dim] =
              (100 * batch + 10 * step + 1* dim) as f32;
        }
    }
}

write_npy::write(&amp;amp;mut wtr, &amp;amp;record); } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Printing the tensor out:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
import numpy as np
dataset = np.load(&quot;test.npy&quot;)
print dataset.shape
print dataset
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```python
    (4, 5, 6)
    [[[(   0.,) (   1.,) (   2.,) (   3.,) (   4.,) (   5.,)]
    [(  10.,) (  11.,) (  12.,) (  13.,) (  14.,) (  15.,)]
    [(  20.,) (  21.,) (  22.,) (  23.,) (  24.,) (  25.,)]
    [(  30.,) (  31.,) (  32.,) (  33.,) (  34.,) (  35.,)]
    [(  40.,) (  41.,) (  42.,) (  43.,) (  44.,) (  45.,)]]&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[[( 100.,) ( 101.,) ( 102.,) ( 103.,) ( 104.,) ( 105.,)]
[( 110.,) ( 111.,) ( 112.,) ( 113.,) ( 114.,) ( 115.,)]
[( 120.,) ( 121.,) ( 122.,) ( 123.,) ( 124.,) ( 125.,)]
[( 130.,) ( 131.,) ( 132.,) ( 133.,) ( 134.,) ( 135.,)]
[( 140.,) ( 141.,) ( 142.,) ( 143.,) ( 144.,) ( 145.,)]]

[[( 200.,) ( 201.,) ( 202.,) ( 203.,) ( 204.,) ( 205.,)]
[( 210.,) ( 211.,) ( 212.,) ( 213.,) ( 214.,) ( 215.,)]
[( 220.,) ( 221.,) ( 222.,) ( 223.,) ( 224.,) ( 225.,)]
[( 230.,) ( 231.,) ( 232.,) ( 233.,) ( 234.,) ( 235.,)]
[( 240.,) ( 241.,) ( 242.,) ( 243.,) ( 244.,) ( 245.,)]]

[[( 300.,) ( 301.,) ( 302.,) ( 303.,) ( 304.,) ( 305.,)]
[( 310.,) ( 311.,) ( 312.,) ( 313.,) ( 314.,) ( 315.,)]
[( 320.,) ( 321.,) ( 322.,) ( 323.,) ( 324.,) ( 325.,)]
[( 330.,) ( 331.,) ( 332.,) ( 333.,) ( 334.,) ( 335.,)]
[( 340.,) ( 341.,) ( 342.,) ( 343.,) ( 344.,) ( 345.,)]]] ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we can load some of these numpy files with PyTorch:&lt;/p&gt;

&lt;p&gt;```python
class orderbookDataset(torch.utils.Dataset):
    def &lt;strong&gt;init&lt;/strong&gt;(self):
        self.data_files = os.listdir(‘data_dir’)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def __getindex__(self, idx):
    return np.load(self.data_files[idx])

def __len__(self):
    return len(self.data_files)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;dset = OrderbookDataset()
loader = torch.utils.DataLoader(dset, num_workers=8)
```&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Using Rust to prepare training set is about as easy as it gets. Amazing language&lt;/p&gt;

&lt;h1 id=&quot;if-you-find-this-article-helpful-you-should-sign-up-to-get-updateshttpstinylettercomrickyhan&quot;&gt;&lt;a href=&quot;https://tinyletter.com/rickyhan&quot;&gt;If you find this article helpful, you should sign up to get updates.&lt;/a&gt;&lt;/h1&gt;
</description>
        <pubDate>Wed, 15 Nov 2017 23:00:00 -0500</pubDate>
        <link>http://rickyhan.com/jekyll/update/2017/11/15/preparing-training-set-with-rust-rayon-npy-format.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2017/11/15/preparing-training-set-with-rust-rayon-npy-format.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Hacking Google reCaptcha</title>
        <description>&lt;p&gt;This post is a detailed breakdown of how to bypass Google reCaptcha.&lt;/p&gt;

&lt;h1 id=&quot;background&quot;&gt;Background&lt;/h1&gt;

&lt;p&gt;“Protected by reCaptcha” means that a form has to be accompanied by a &lt;code class=&quot;highlighter-rouge&quot;&gt;g-recaptcha-response&lt;/code&gt; field, which is then verified by the backend through a request to reCaptcha server. Based on the probability calculated by a machine learning algorithm, reCaptcha may give you captchas with difficulty nonexistent, very hard and everything in between. Instead of having to solve the captcha by hand, this method allows using another valid browser session cookie which Google deems “human” to effectively bypass a captcha. These “valid” browser sessions can be farmed en masse. According to &lt;a href=&quot;https://www.blackhat.com/docs/asia-16/materials/asia-16-Sivakorn-Im-Not-a-Human-Breaking-the-Google-reCAPTCHA-wp.pdf&quot;&gt;this report&lt;/a&gt;, “[…] a checkbox captcha is obtained after the beginning of the 9th day from the cookie’s creation, without requiring any browsing activities and type of network connection […]. Our experiment also revealed that each cookie can receive up to 8 checkbox captchas in a day.”&lt;/p&gt;

&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;

&lt;p&gt;I used a simple nodejs server that serves a form to collect Google reCaptcha response. The caveat is: the browser must have the same hostname as the real website which is achieved by changing the &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/hosts&lt;/code&gt; file or hosting a DNS server.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/0QqEQDI.png&quot; alt=&quot;harvestor&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;javascript
app.post(&#39;/submit&#39;, function(req, res) {
  log(&#39;info&#39;, `Successful Token: ${req.body[&#39;g-recaptcha-response&#39;]}`);
  const token = req.body[&#39;g-recaptcha-response&#39;];
  const timestamp = new Date();
  saveToken(token, timestamp);
  return res.redirect(`${config.remotehost}:${app.get(&#39;port&#39;)}/harvest`);
});
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;On the other hand, I am using a browser automation tool to submit a form which is protected by recaptcha. We need &lt;code class=&quot;highlighter-rouge&quot;&gt;g-recaptcha-response&lt;/code&gt; in a hidden field. So when the page is loaded, we &lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt; for a valid token:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;js
await validToken(pageLoadedTime)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And this then sends a message to all connected harvestors via websocket:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;js
function validToken(pageLoadedTime) {
    wss.broadcast(&#39;needtoken&#39;);
    return new Promise((resolve, reject) =&amp;gt; {
        (function wait() {
            for (let token of tokens)
                if (token.timestamp.getTime() &amp;gt; pageLoadedTime)
                    resolve(token.token);
            setTimeout( wait, 200 );
        })();
    });
}
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We use &lt;a href=&quot;https://developers.google.com/recaptcha/docs/invisible&quot;&gt;invisible recaptcha&lt;/a&gt; on the harvestor page, because its actions can be programmatically triggered.&lt;/p&gt;

&lt;p&gt;```html&lt;/p&gt;
&lt;div class=&quot;g-recaptcha&quot; data-sitekey=&quot;&amp;lt;%= sitekey %&amp;gt;&quot; data-callback=&quot;sub&quot; data-size=&quot;invisible&quot;&gt;&lt;/div&gt;
&lt;script&gt;
  function sub(){
    document.getElementById(&quot;submit&quot;).click();
  }
  var wss = new WebSocket(&quot;ws://www.hostname.com:8080&quot;, &quot;protocolOne&quot;);
  wss.onmessage = function (event) {
    if(&quot;needtoken&quot; === event.data) {
      grecaptcha.execute();
    } else {
      console.log(&quot;CONNECTED&quot;);
    }
  }
&lt;/script&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Now, there is a way to farm these valid harvestor sessions such that the first 20 or so recaptcha verifications are bypassed. Now the automated browser window has a valid reCaptcha, it needs to fill the hidden field and call the callback function! Great work Google!&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;js
return nightmare
.evaluate((key) =&amp;gt; {
    document.getElementById(&quot;g-recaptcha-response&quot;).innerHTML = key;
    checkoutAfterCaptcha();
}, await validToken(pageLoadedTime))
.wait(2000)
.screenshot(&#39;ok.png&#39;)
.end();
&lt;/code&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Nov 2017 23:00:00 -0500</pubDate>
        <link>http://rickyhan.com/jekyll/update/2017/11/09/bypassing-recaptcha.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2017/11/09/bypassing-recaptcha.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Gradient Trader Part 3: Efficient Storage of Order Book Data</title>
        <description>&lt;p&gt;Dealing with order book data is a problem everyone encounters at some point. The more professional a firm is, the more severe the problem gets.&lt;/p&gt;

&lt;p&gt;As documented in a &lt;a href=&quot;http://rickyhan.com/jekyll/update/2017/09/09/import-orderbook-from-exchanges.html&quot;&gt;previous post&lt;/a&gt;, I have been storing order book ticks to a PostgreSQL. Using an out-of-the-box solution seems like a good idea at first, but it stops working before you notice. After amassing a whopping 2 terabytes of data, the system gradually slowed down. In the meantime, I have been working on a datastore specifically for storing order book updates. It uses a compressed binary file and stores one row in 12 bytes. This post is a short overview of how it is implemented. At its current stage, it is a filesystem backed append-only storage. The complexity is nowhere near SecDB, Athena, Quartz. In the future, I plan on adding clustering, master-slave replication, implement a better DSL, events, and &lt;a href=&quot;https://medium.com/@istanbul_techie/a-look-at-conflict-free-replicated-data-types-crdt-221a5f629e7e&quot;&gt;CRDT&lt;/a&gt; should the demand arise.&lt;/p&gt;

&lt;h2 id=&quot;dense-tick-format-dtf--thinking-about-compression&quot;&gt;Dense Tick Format (.dtf) : thinking about compression&lt;/h2&gt;

&lt;p&gt;First of all, structure data can be compressed. The key is finding a sweet spot between processing speed and storage efficiency. If you have read my previous posts, you will know that the contiguous data is of this shape:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;json
{
    &quot;ts&quot;: 509129207.487,
    &quot;seq&quot;: 79683,
    &quot;is_trade&quot;: false,
    &quot;is_bid&quot;: false,
    &quot;price&quot;: 0.00540787,
    &quot;size&quot;: 1.2227914
}
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;These 6 fields are the minimal amount of information to reconstruct the order book in its entirety. (&lt;a href=&quot;http://rickyhan.com/jekyll/update/2017/09/24/visualizing-order-book.html&quot;&gt;Note on reconstruction&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&quot;naive-approach&quot;&gt;Naive approach&lt;/h3&gt;

&lt;p&gt;The naive approach is to use a CSV file. Storing it in plaintext (like txt) would require 45 bytes. Text file is neither efficient in storage nor in processing speed. We will compare our codecs against this baseline.&lt;/p&gt;

&lt;h3 id=&quot;our-first-codec&quot;&gt;Our first codec&lt;/h3&gt;

&lt;p&gt;Let’s do the bare minimum. Switching from ascii (1 byte per char), we use default data types to encode the same information:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
ts (u32): int
seq (u32): int
is_trade: (u8): bool
is_bid: (u8): bool
price: (f32): float
size: (f32): float
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Timestamp is stored as an unsigned integer by multiplying the float by 1000.&lt;/p&gt;

&lt;p&gt;Sums up to &lt;code class=&quot;highlighter-rouge&quot;&gt;4 + 4 + 1 + 1 + 4 + 4 = 18 bytes&lt;/code&gt;, a 60% reduction. This approach also takes significantly less time because string parsing is unnecessary. However, there are still plenty of low hanging fruits.&lt;/p&gt;

&lt;h3 id=&quot;bitflags&quot;&gt;Bitflags&lt;/h3&gt;

&lt;p&gt;Note how the bool is stored as a whole byte when it only takes 1 bit. This is because a byte is the smallest addressable unit in memory. We can squish the two bools into 1 byte by using bitflags. Now we have 17 bytes, a 5% reduction.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
ts (u32)
seq (u32)
((is_trade &amp;lt;&amp;lt; 1) | is_bid): (u8)
price: (f32)
size: (f32)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To do this, I used the &lt;code class=&quot;highlighter-rouge&quot;&gt;bitflags&lt;/code&gt; crate in Rust.&lt;/p&gt;

&lt;p&gt;```rust
// use bitflags macro to define a struct
bitflags! {
    struct Flags: u8 {
        const FLAG_EMPTY   = 0b0000_0000;
        const FLAG_IS_BID   = 0b0000_0001;
        const FLAG_IS_TRADE = 0b0000_0010;
    }
}&lt;/p&gt;

&lt;p&gt;let mut flags = Flags::FLAG_EMPTY;
if self.is_bid { flags |= Flags::FLAG_IS_BID; }
if self.is_trade { flags |= Flags::FLAG_IS_TRADE; }
let _ = buf.write_u8(flags.bits());
```&lt;/p&gt;

&lt;h3 id=&quot;delta-encoding&quot;&gt;Delta encoding&lt;/h3&gt;

&lt;p&gt;Instead of storing each tick as its own row, we can exploit the shared structure along the time axis, namely taking snapshot of time and sequence number. Since &lt;code class=&quot;highlighter-rouge&quot;&gt;timestamp&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;seq&lt;/code&gt; are discretely increasing fields, we can create a snapshot the usual size (int) and store the difference in a smaller data type(short). This method is called delta encoding.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
0. bool for is_snapshot
1. if snapshot
    4 bytes (u32): reference ts
    2 bytes (u32): reference seq
    2 bytes (u16): how many records between this snapshot and the next snapshot
2. record
    dts (u16): $ts - reference ts$, 2^16 = 65536 ms = ~65 seconds
    dseq (u8) $seq - reference seq$ , 2^8 = 256
    (is_trade &amp;lt;&amp;lt; 1) | is_bid`: (u8): bitwise and to store two bools in one byte
    price: (f32)
    size: (f32)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The idea is to save a snapshot every once in a while, and everytime when &lt;code class=&quot;highlighter-rouge&quot;&gt;dts&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;dseq&lt;/code&gt; are close to overflow, start a new snapshot and repeat. This on average saves 5 bytes, a 30% reduction. And the processing overhead is &lt;code class=&quot;highlighter-rouge&quot;&gt;O(1)&lt;/code&gt;. Here, we use only 12 bytes, 27% of the original codec.&lt;/p&gt;

&lt;p&gt;There are other ways to futher reduce the size if we aren’t storing the whole order book. For example, contiguous tick prices tend to be close to each other, which means &lt;a href=&quot;https://gist.github.com/mfuerstenau/ba870a29e16536fdbaba&quot;&gt;zigzag encoding&lt;/a&gt; can be useful. If the price only goes upward(possible with a hypothetical ponzi scheme based funds), we can use &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/encoding&quot;&gt;varint&lt;/a&gt;. Also, doing delta encoding over the bytes could potentially save a few bytes, but would cost O(n) in additional processing time, same with run length encoding: first run a decompression over bytes, then decompress again.&lt;/p&gt;

&lt;h3 id=&quot;metadata&quot;&gt;Metadata&lt;/h3&gt;

&lt;p&gt;We also need to store metadata about the dtf file in the header.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
Offset 00: ([u8; 5]) magic value 0x4454469001 (DTF9001)
Offset 05: ([u8; 20]) Symbol
Offset 25: (u64) number of records
Offset 33: (u32) max ts
Offset 80: -- records - see below --
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;First put a magic value to identify the kind of file. Then store the symbol and exchange for the file in 20 characters. Then number of records and maximum timestamp so during decoding, it is unnecessary to read the entire file to find this information.&lt;/p&gt;

&lt;p&gt;When dealing with large amount of structured data, it makes sense to build a simple binary file format to increase storage and processing efficiency.&lt;/p&gt;

&lt;p&gt;If you want to learn more about file encodings, take a look at the &lt;a href=&quot;https://github.com/sripathikrishnan/redis-rdb-tools/wiki/Redis-RDB-Dump-File-Format&quot;&gt;spec for redis files&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;read-write-traits&quot;&gt;Read, Write traits&lt;/h3&gt;

&lt;p&gt;The above encoder/decoder can support a multitude of buffers: BufWriter, TcpStream, String, etc… thanks to the trait system in Rust. As long as the buffer struct implements &lt;code class=&quot;highlighter-rouge&quot;&gt;Read&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Write&lt;/code&gt; traits, it can used to transfer or store orderbook ticks. This saves a lot of boilerplate.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rust
fn write_magic_value(wtr: &amp;amp;mut Write) {
    let _ = wtr.write(MAGIC_VALUE);
}
&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;designing-a-tcp-server&quot;&gt;Designing a TCP Server&lt;/h2&gt;

&lt;p&gt;Now that a format is in place, it’s time to build a TCP server and start serving requests.&lt;/p&gt;

&lt;h3 id=&quot;design&quot;&gt;Design&lt;/h3&gt;

&lt;p&gt;We break the problem down into these subproblems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;a shared state that is thread-safe&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;threadpool for capping the number of connections&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;each client needs its own thread and a separate state&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;threading&quot;&gt;Threading&lt;/h3&gt;

&lt;p&gt;This is my first naive implementation: spawn a separate thread when a new client connects.&lt;/p&gt;

&lt;p&gt;```rust
let listener = match TcpListener::bind(&amp;amp;addr) {
    Ok(listner) =&amp;gt; listener,
    Err(e) =&amp;gt; panic!(format!(“”, e.description()))
};&lt;/p&gt;

&lt;p&gt;for stream in listener.incoming() {
    let stream = stream.unwrap();
    thread.spawn(move || {
        let mut buf = [0; 2048];
        loop {
            let bytes_read = stream.read(&amp;amp;mut buf).unwrap();
            if bytes_read == 0 { break }
            let req = str::from_utf8(&amp;amp;buf[..(bytes_read-1)]).unwrap();
            for line in req.split(‘\n’) {
                stream.write(“Response”.as_bytes()).unwrap()
            }
        }
    })
}
```&lt;/p&gt;

&lt;p&gt;However, when a client goes haywire and opens up millions of connections, the server will eventually run out of memory and segfault. To cap the number of connections, use a threadpool.&lt;/p&gt;

&lt;h3 id=&quot;threadpool&quot;&gt;Threadpool&lt;/h3&gt;

&lt;p&gt;The threadpool implementation is covered in the Rust book. It is interesting because it covers pretty much all grounds of Rust syntax and idiosyncrasies.&lt;/p&gt;

&lt;p&gt;```rust
use std::thread;
use std::sync::{mpsc, Arc, Mutex};&lt;/p&gt;

&lt;p&gt;enum Message {
    NewJob(Job),
    Terminate,
}&lt;/p&gt;

&lt;p&gt;pub struct ThreadPool {
    workers: Vec&lt;worker&gt;,
    sender: mpsc::Sender&lt;message&gt;,
}&lt;/message&gt;&lt;/worker&gt;&lt;/p&gt;

&lt;p&gt;trait FnBox {
    fn call_box(self: Box&lt;self&gt;);
}&lt;/self&gt;&lt;/p&gt;

&lt;p&gt;impl&amp;lt;F: FnOnce()&amp;gt; FnBox for F {
    fn call_box(self: Box&lt;f&gt;) {
        (*self)()
    }
}&lt;/f&gt;&lt;/p&gt;

&lt;p&gt;type Job = Box&amp;lt;FnBox + Send + ‘static&amp;gt;;&lt;/p&gt;

&lt;p&gt;impl ThreadPool {
    pub fn new(size: usize) -&amp;gt; ThreadPool {
        assert!(size &amp;gt; 0);
        let (sender, receiver) = mpsc::channel();
        let receiver = Arc::new(Mutex::new(receiver));
        let mut workers = Vec::with_capacity(size);
        for id in 0..size {
            workers.push(Worker::new(id, receiver.clone()));
        }
        ThreadPool {
            workers,
            sender,
        }
    }
    pub fn execute&lt;f&gt;(&amp;amp;self, f: F)
        where
            F: FnOnce() + Send + &#39;static
    {
        let job = Box::new(f);&lt;/f&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    self.sender.send(Message::NewJob(job)).unwrap();
} }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;impl Drop for ThreadPool {
    fn drop(&amp;amp;mut self) {
        for _ in &amp;amp;mut self.workers {
            self.sender.send(Message::Terminate).unwrap();
        }
        for worker in &amp;amp;mut self.workers {
            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}
struct Worker {
    id: usize,
    thread: Option&amp;lt;thread::JoinHandle&amp;lt;()»,
}
impl Worker {
    fn new(id: usize, receiver: Arc&amp;lt;Mutex&amp;lt;mpsc::Receiver&lt;message&gt;&amp;gt;&amp;gt;) -&amp;gt;
        Worker {
        let thread = thread::spawn(move ||{
            loop {
                let message = receiver.lock().unwrap().recv().unwrap();
                match message {
                    Message::NewJob(job) =&amp;gt; {
                        job.call_box();
                    },
                    Message::Terminate =&amp;gt; {
                        break;
                    },
                }
            }
        });
        Worker {
            id,
            thread: Some(thread),
        }
    }
}
```&lt;/message&gt;&lt;/p&gt;

&lt;p&gt;The implementation is straightforward, we store the workers in a Vec. As long as the workers are not exhausted, we assign an FnOnce closure and the worker does job exactly once.&lt;/p&gt;

&lt;p&gt;Arc stands for atomic reference counting. Because Rc is not designed for use in multiple threads, it is not safe to be shared between threads. Arc can be shared. In Rust, there are two important traits to ensure thread safety: &lt;code class=&quot;highlighter-rouge&quot;&gt;Send&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Sync&lt;/code&gt;. The two traits usually appears in pair. &lt;code class=&quot;highlighter-rouge&quot;&gt;Send&lt;/code&gt; means you can send the data to threads safely without trigger a deepcopy, and the compiler will implement Send for you when deemed fit. Basically, &lt;code class=&quot;highlighter-rouge&quot;&gt;Arc::clone(&amp;amp;locked_obj)&lt;/code&gt; creates an atomic reference that can be sent(as in &lt;code class=&quot;highlighter-rouge&quot;&gt;mpsc&lt;/code&gt;) or move to another thread(as in &lt;code class=&quot;highlighter-rouge&quot;&gt;move&lt;/code&gt; closure). By clone an Arc, the reference count is incremented. When the clone is dropped, the counter is decremented. When all the references across all threads are destroyed, such that &lt;code class=&quot;highlighter-rouge&quot;&gt;count == 0&lt;/code&gt;, then the chunk of memory is released. &lt;code class=&quot;highlighter-rouge&quot;&gt;Sync&lt;/code&gt; means every modification to the data will be synchronized between the threads, it is what &lt;code class=&quot;highlighter-rouge&quot;&gt;Mutex&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;RwLock&lt;/code&gt; are for.&lt;/p&gt;

&lt;p&gt;To use threadpool, simply replace &lt;code class=&quot;highlighter-rouge&quot;&gt;thread::spawn&lt;/code&gt; with 
&lt;code class=&quot;highlighter-rouge&quot;&gt;rust
let pool = ThreadPool::new(settings.threads);
for stream in listener.incoming() {
    let stream = stream.unwrap();
    pool.execute(move || {
        handle(&amp;amp;stream);
    });
}
&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;shared-state&quot;&gt;Shared state&lt;/h3&gt;

&lt;p&gt;Next we define a global state that allows a number of readers but only one writer can acquire the lock.&lt;/p&gt;

&lt;p&gt;```rust
struct SharedState {
    pub connections: u16,
    pub settings: Settings,
    pub vec_store: HashMap&amp;lt;String, VecStore&amp;gt;,
    pub history: History,
}&lt;/p&gt;

&lt;p&gt;impl SharedState {
    pub fn new(settings: Settings) -&amp;gt; SharedState {
        let mut hashmap = HashMap::new();
        hashmap.insert(“default”.to_owned(), (Vec::new(),0) );
        SharedState {
            connections: 0,
            settings,
            vec_store: hashmap,
            history: HashMap::new(),
        }
    }
}&lt;/p&gt;

&lt;p&gt;let global = Arc::new(RwLock::new(SharedState::new(settings.clone())));&lt;/p&gt;

&lt;p&gt;for stream in listener.incoming() {
    let stream = stream.unwrap();
    let global_copy = global.clone();
    pool.execute(move || {
        on_connect(&amp;amp;global_copy);
        handle_client(stream, &amp;amp;global_copy);
        on_disconnect(&amp;amp;global_copy);
    });
}&lt;/p&gt;

&lt;p&gt;fn on_connect(global: &amp;amp;LockedGlobal) {
    {
        let mut glb_wtr = global.write().unwrap();
        glb_wtr.connections += 1;
    }&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;info!(&quot;Client connected. Current: {}.&quot;, global.read().unwrap().connections); }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;fn on_disconnect(global: &amp;amp;LockedGlobal) {
    {
        let mut glb_wtr = global.write().unwrap();
        glb_wtr.connections -= 1;
    }&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let rdr = global.read().unwrap();
info!(&quot;Client connection disconnected. Current: {}.&quot;, rdr.connections); } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SharedState&lt;/code&gt; is a state that all children processes have access to. &lt;code class=&quot;highlighter-rouge&quot;&gt;connections&lt;/code&gt; is a count of how many clients are connected, &lt;code class=&quot;highlighter-rouge&quot;&gt;settings&lt;/code&gt; is a shared copy of the setting, &lt;code class=&quot;highlighter-rouge&quot;&gt;vec_store&lt;/code&gt; stores the Updates and &lt;code class=&quot;highlighter-rouge&quot;&gt;history&lt;/code&gt; records usage statistics.&lt;/p&gt;

&lt;p&gt;As a demonstration of modifying a mutable shared state, here is duplication of the code to append to &lt;code class=&quot;highlighter-rouge&quot;&gt;history&lt;/code&gt;. Spawn another thread that executes every x seconds depends on the desired granularity.&lt;/p&gt;

&lt;p&gt;```rust
// Timer for recording history
{
    let global_copy_timer = global.clone();
    let granularity = settings.hist_granularity.clone();
    thread::spawn(move || {
        let dur = time::Duration::from_secs(granularity);
        loop {
            {
                let mut rwdr = global_copy_timer.write().unwrap();
                let (total, sizes) = {
                    let mut total = 0;
                    let mut sizes: Vec&amp;lt;(String, u64)&amp;gt; = Vec::new();
                    for (name, vec) in rwdr.vec_store.iter() {
                        let size = vec.1;
                        total += size;
                        sizes.push((name.clone(), size));
                    }
                    sizes.push((“total”.to_owned(), total));
                    (total, sizes)
                };&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;            let current_t = time::SystemTime::now();
            for &amp;amp;(ref name, size) in sizes.iter() {
                if !rwdr.history.contains_key(name) {
                    rwdr.history.insert(name.clone(), Vec::new());
                }
                rwdr.history.get_mut(name)
                            .unwrap()
                            .push((current_t, size));
            }

            info!(&quot;Current total count: {}&quot;, total);
        }

        thread::sleep(dur);
    }
}); } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This piece of code is pretty bizarre at a first glance due to the usage of scopes. Rust has a particular take on scoping: especially with Locks. Basically, obtaining a lock&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;let mut rwdr = global_copy_timer.write().unwrap();&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;returns a &lt;code class=&quot;highlighter-rouge&quot;&gt;RwLockWriteGuard&lt;/code&gt;. When it goes out scope(&lt;code class=&quot;highlighter-rouge&quot;&gt;Drop&lt;/code&gt;ped), the exclusive write access is released. This means we must have read lock and write lock in separate scopes, or else we’ll end up in a deadlock. In this case, since the write lock should be released when the thread is sleeping, it is dropped explicitly.&lt;/p&gt;

&lt;h3 id=&quot;counting&quot;&gt;Counting&lt;/h3&gt;

&lt;p&gt;The idea is to automatically flush to disk on every 10k inserts and clear the memory. This is done by recording two sizes: a nominal count: rows in memory plus rows in files; and an actual count of rows in memory. When the rows in memory exceeds a threshold, append to the file and clear memory. Then, when another client needs historical data, the server can load data from file without affecting the count.&lt;/p&gt;

&lt;p&gt;Here is the implementation of auto flush:&lt;/p&gt;

&lt;p&gt;```rust
pub fn add(&amp;amp;mut self, new_vec : dtf::Update) {
    let is_autoflush = {
        let mut wtr = self.global.write().unwrap();
        let is_autoflush = wtr.settings.autoflush;
        let flush_interval = wtr.settings.flush_interval;
        let folder = wtr.settings.dtf_folder.to_owned();
        let vecs = wtr.vec_store.get_mut(&amp;amp;self.name).expect(“KEY IS NOT IN HASHMAP”);&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    vecs.0.push(new_vec);
    vecs.1 += 1;

    // Flush current store into disk after n items is inserted.
    let size = vecs.0.len();
    let is_autoflush = is_autoflush
                    &amp;amp;&amp;amp; size != 0
                    &amp;amp;&amp;amp; (size as u32) % flush_interval == 0;
    if is_autoflush {
        debug!(&quot;AUTOFLUSHING {}! Size: {} Last: {:?}&quot;, self.name, size, vecs.0.last().clone().unwrap());
    }
    is_autoflush
};
if is_autoflush {
    self.flush();
} } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;self&lt;/code&gt; is borrowed in the first line so we have to manually create a scope to drop &lt;code class=&quot;highlighter-rouge&quot;&gt;self&lt;/code&gt;. This piece of code is a good (bad?) example of how Rust developers fight the compiler. This makes memory management a LOT cleaner and way more tractable.&lt;/p&gt;

&lt;h3 id=&quot;command-parser&quot;&gt;Command Parser&lt;/h3&gt;

&lt;p&gt;The command parser is still rudimentary as it is implemented using a series of match and if-else statements similar to Redis. However, it gets the job done. I will refactor this should demand arise.&lt;/p&gt;

&lt;p&gt;Here is a list of commands:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PING&lt;/li&gt;
  &lt;li&gt;HELP&lt;/li&gt;
  &lt;li&gt;INFO&lt;/li&gt;
  &lt;li&gt;PERF&lt;/li&gt;
  &lt;li&gt;COUNT&lt;/li&gt;
  &lt;li&gt;COUNT ALL&lt;/li&gt;
  &lt;li&gt;CREATE [db]&lt;/li&gt;
  &lt;li&gt;USE [db]&lt;/li&gt;
  &lt;li&gt;ADD [row]&lt;/li&gt;
  &lt;li&gt;ADD [row] INTO [db]&lt;/li&gt;
  &lt;li&gt;BULKADD&lt;/li&gt;
  &lt;li&gt;BULKADD INTO [db]&lt;/li&gt;
  &lt;li&gt;CLEAR&lt;/li&gt;
  &lt;li&gt;CLEAR ALL&lt;/li&gt;
  &lt;li&gt;FLUSH&lt;/li&gt;
  &lt;li&gt;FLUSH ALL&lt;/li&gt;
  &lt;li&gt;GET [count]&lt;/li&gt;
  &lt;li&gt;GET [count] AS JSON&lt;/li&gt;
  &lt;li&gt;GET ALL&lt;/li&gt;
  &lt;li&gt;GET ALL AS JSON&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If not specified &lt;code class=&quot;highlighter-rouge&quot;&gt;AS JSON&lt;/code&gt;, it uses the above serialization format.&lt;/p&gt;

&lt;h2 id=&quot;tools&quot;&gt;Tools&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dtfcat&lt;/code&gt; is a simple reader for &lt;code class=&quot;highlighter-rouge&quot;&gt;.dtf&lt;/code&gt; files. It can read metadata, convert dtf to csv, rebin and split into smaller files by time buckets.&lt;/p&gt;

&lt;h2 id=&quot;client-implementations&quot;&gt;Client implementations&lt;/h2&gt;

&lt;p&gt;I had some trouble writing a client in JavaScript. Here is an implementation in TypeScript:&lt;/p&gt;

&lt;p&gt;```typescript
const net = require(‘net’);
const THREADS = 20;
const PORT = 9001;
const HOST = ‘localhost’;&lt;/p&gt;

&lt;p&gt;import { DBUpdate } from ‘../typings’;&lt;/p&gt;

&lt;p&gt;interface TectonicResponse {
    success: boolean;
    data: string;
}&lt;/p&gt;

&lt;p&gt;type SocketMsgCb = (res: TectonicResponse) =&amp;gt; void;&lt;/p&gt;

&lt;p&gt;export interface SocketQuery {
    message: string;
    cb: SocketMsgCb;
    onError: (err: any) =&amp;gt; void;
}&lt;/p&gt;

&lt;p&gt;export default class TectonicDB {
    port : number;
    address : string;
    socket: any;
    initialized: boolean;
    dead: boolean;
    private onDisconnect: any;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private socketSendQueue: SocketQuery[];
private activeQuery?: SocketQuery;
private readerBuffer: Buffer;

// tslint:disable-next-line:no-empty
constructor(port=PORT, address=HOST, onDisconnect=((queue: SocketQuery[]) =&amp;gt; { })) {
    this.socket = new net.Socket();
    this.activeQuery = null;
    this.address = address || HOST;
    this.port = port || PORT;
    this.initialized = false;
    this.dead = false;
    this.onDisconnect = onDisconnect;
    this.init();
}

async init() {
    const client = this;

    client.socketSendQueue = [];
    client.readerBuffer = new Buffer([]);

    client.socket.connect(client.port, client.address, () =&amp;gt; {
        // console.log(`Tectonic client connected to: ${client.address}:${client.port}`);
        this.initialized = true;

        // process any queued queries
        if(this.socketSendQueue.length &amp;gt; 0) {
            // console.log(&#39;Sending queued message after DB connected...&#39;);
            client.activeQuery = this.socketSendQueue.shift();
            client.sendSocketMsg(this.activeQuery.message);
        }
    });

    client.socket.on(&#39;close&#39;, () =&amp;gt; {
        // console.log(&#39;Client closed&#39;);
        client.dead = true;
        client.onDisconnect(client.socketSendQueue);
    });

    client.socket.on(&#39;data&#39;, (data: any) =&amp;gt;
        this.handleSocketData(data));

    client.socket.on(&#39;error&#39;, (err: any) =&amp;gt; {
        if(client.activeQuery) {
            client.activeQuery.onError(err);
        }
    });
}

// skipped some functions

async bulkadd_into(updates : DBUpdate[], db: string) {
    const ret = [];
    ret.push(&#39;BULKADD INTO &#39;+ db);
    for (const { timestamp, seq, is_trade, is_bid, price, size} of updates) {
        ret.push(`${timestamp}, ${seq}, ${is_trade ? &#39;t&#39; : &#39;f&#39;}, ${is_bid ? &#39;t&#39;:&#39;f&#39;}, ${price}, ${size};`);
    }
    ret.push(&#39;DDAKLUB&#39;);
    this.cmd(ret);
}

async use(dbname: string) {
    return this.cmd(`USE ${dbname}`);
}

handleSocketData(data: Buffer) {
    const client = this;

    const totalLength = client.readerBuffer.length + data.length;
    client.readerBuffer = Buffer.concat([client.readerBuffer, data], totalLength);

    // check if received a full response from stream, if no, store to buffer.
    const firstResponse = client.readerBuffer.indexOf(0x0a); // chr(0x0a) == &#39;\n&#39;
    if (firstResponse === -1) { // newline not found
        return;
    } else {
        // data up to first newline
        const data = client.readerBuffer.subarray(0, firstResponse+1);
        // remove up to first newline
        const rest = client.readerBuffer.subarray(firstResponse+1, client.readerBuffer.length);
        client.readerBuffer = new Buffer(rest);

        const success = data.subarray(0, 8)[0] === 1;
        const len = new Uint32Array(data.subarray(8,9))[0];
        const dataBody : string = String.fromCharCode.apply(null, data.subarray(9, 12+len));
        const response : TectonicResponse = {success, data: dataBody};

        if (client.activeQuery) {
            // execute the stored callback with the result of the query, fulfilling the promise
            client.activeQuery.cb(response);
        }

        // if there&#39;s something left in the queue to process, do it next
        // otherwise set the current query to empty
        if(client.socketSendQueue.length === 0) {
            client.activeQuery = null;
        } else {
            // equivalent to `popFront()`
            client.activeQuery = this.socketSendQueue.shift();
            client.sendSocketMsg(client.activeQuery.message);
        }
    }
}

sendSocketMsg(msg: string) {
    this.socket.write(msg+&#39;\n&#39;);
}

cmd(message: string | string[]) : Promise&amp;lt;TectonicResponse&amp;gt; {
    const client = this;
    let ret: Promise&amp;lt;TectonicResponse&amp;gt;;

    if (Array.isArray(message)) {
         ret = new Promise((resolve, reject) =&amp;gt; {
            for (const m of message) {
                client.socketSendQueue.push({
                    message: m,
                    cb: m === &#39;DDAKLUB&#39; ? resolve : () =&amp;gt; {},
                    onError: reject,
                });
            }
        });
    } else if (typeof message === &#39;string&#39;) {
        ret = new Promise((resolve, reject) =&amp;gt; {
            const query: SocketQuery = {
                message,
                cb: resolve,
                onError: reject,
            };
            client.socketSendQueue.push(query);
        });
    }

    if (client.activeQuery == null &amp;amp;&amp;amp; this.initialized) {
        client.activeQuery = this.socketSendQueue.shift();
        client.sendSocketMsg(client.activeQuery.message);
    }

    return ret;
}

exit() {
    this.socket.destroy();
}

getQueueLen(): number {
    return this.socketSendQueue.length;
}

concatQueue(otherQueue: SocketQuery[]) {
    this.socketSendQueue = this.socketSendQueue
                            .concat(otherQueue);
} } ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It uses a FIFO queue to keep the db calls in order.&lt;/p&gt;

&lt;p&gt;There is also a connection pool class for distributing loads. It was quite an undertaking.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;You’ve made it this far, congrats! Here is a screenshot of tectonic running in semi-production:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/PttCo1v.png&quot; alt=&quot;TectonicDB in action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It inserts ~100k records every 30 seconds. or 3000 inserts per second. Hope this post is helpful to your own development.&lt;/p&gt;

&lt;p&gt;I am pretty happy with the end result. The database compiles to a 4mb binary executable and can handle millions of inserts per second. The bottleneck was always the client.&lt;/p&gt;

&lt;p&gt;Although Rust is not the fastest language to prototype with, the compiler improves the quality of life drastically.&lt;/p&gt;

&lt;h1 id=&quot;improvement&quot;&gt;Improvement&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Python client.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sharding&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Event dispatch. Similar to PostgreSQL’s event system.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Master-slave replication&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 27 Oct 2017 22:37:01 -0400</pubDate>
        <link>http://rickyhan.com/jekyll/update/2017/10/27/how-to-handle-order-book-data.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2017/10/27/how-to-handle-order-book-data.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Running Factorio on SONM</title>
        <description>&lt;p&gt;In this short post, I will test out SONM.&lt;/p&gt;

&lt;p&gt;SONM is a decentralized cloud provider. In this case, cloud is just someone else’s computer literally. I read on the website that this is called “fog computing.” In essense, anyone can become a “miner” to run application in exchange for SONM tokens. The technology is enabled by Docker, Yandex Cocaine and its own network discovery module(insomnia) and a blockchain interface. There are two binaries: hub for discovery(presumably one for a computing cluster) and miner to run on each host machine, both written in Go. I’d like to think of SONM as Kubernetes on a blockchain.&lt;/p&gt;

&lt;p&gt;To test the project at its current stage, I will deploy a Factorio docker server and judge by the ease of use for both sysadmin and end user.&lt;/p&gt;

&lt;h1 id=&quot;installing-sonm-toolbelt&quot;&gt;Installing SONM Toolbelt&lt;/h1&gt;

&lt;p&gt;Following alpha release &lt;a href=&quot;https://sonm.io/alpha-release/&quot;&gt;the tutorial&lt;/a&gt; step by step, I downloaded the 0.2.1 release from &lt;a href=&quot;https://github.com/sonm-io/core/releases&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./sonmhub
INFO [10-12|19:26:40] Starting P2P networking 
INFO [10-12|19:26:42] UDP listener up                          self=enode://b1ac08dd98423379ed75a4ea28ea5f4d96896743a8648d7c20880f79378a13ef910e8e2d98c50c01fa2442d7ffd5811a3ce25650f8592aa3ee2ae10970f5b7a4@207.244.97.166:30343
INFO [10-12|19:26:42] Whisper started 
2017-10-12T19:26:42.982Z        INFO    hub/server.go:288       listening for connections from Miners   {&quot;address&quot;: &quot;[::]:10002&quot;}
2017-10-12T19:26:42.984Z        INFO    hub/server.go:297       listening for gRPC API connections      {&quot;address&quot;: &quot;[::]:10001&quot;}
INFO [10-12|19:26:42] RLPx listener up                         self=enode://b1ac08dd98423379ed75a4ea28ea5f4d96896743a8648d7c20880f79378a13ef910e8e2d98c50c01fa2442d7ffd5811a3ce25650f8592aa3ee2ae10970f5b7a4@207.244.97.166:30343
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then in a separate session,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo ./sonmminer 
2017-10-12T19:27:09.595Z        DEBUG   miner/builder.go:75     building a miner        {&quot;config&quot;: {&quot;HubConfig&quot;:{&quot;Endpoint&quot;:&quot;127.0.0.1:10002&quot;,&quot;Resources&quot;:null},&quot;FirewallConfig&quot;:null,&quot;GPUConfig&quot;:null,&quot;SSHConfig&quot;:null,&quot;LoggingConfig&quot;:{&quot;Level&quot;:-1}}}
2017-10-12T19:27:09.603Z        DEBUG   miner/builder.go:83     discovering public IP address ...
2017-10-12T19:27:09.611Z        INFO    miner/builder.go:109    discovered public IP address    {&quot;addr&quot;: &quot;207.244.97.166&quot;, &quot;nat&quot;: &quot;Not behind a NAT&quot;}
2017-10-12T19:27:09.611Z        INFO    miner/builder.go:140    collected Hardware info {&quot;hardware&quot;: {&quot;CPU&quot;:[{&quot;cpu&quot;:0,&quot;vendorId&quot;:&quot;GenuineIntel&quot;,&quot;family&quot;:&quot;6&quot;,&quot;model&quot;:&quot;2&quot;,&quot;stepping&quot;:3,&quot;physicalId&quot;:&quot;0&quot;,&quot;coreId&quot;:&quot;0&quot;,&quot;cores&quot;:1,&quot;modelName&quot;:&quot;QEMU Virtual CPU version 1.2.1&quot;,&quot;mhz&quot;:2400.082,&quot;cacheSize&quot;:4096,&quot;flags&quot;:[&quot;fpu&quot;,&quot;de&quot;,&quot;pse&quot;,&quot;tsc&quot;,&quot;msr&quot;,&quot;pae&quot;,&quot;mce&quot;,&quot;cx8&quot;,&quot;apic&quot;,&quot;sep&quot;,&quot;mtrr&quot;,&quot;pge&quot;,&quot;mca&quot;,&quot;cmov&quot;,&quot;pse36&quot;,&quot;clflush&quot;,&quot;mmx&quot;,&quot;fxsr&quot;,&quot;sse&quot;,&quot;sse2&quot;,&quot;syscall&quot;,&quot;nx&quot;,&quot;lm&quot;,&quot;rep_good&quot;,&quot;nopl&quot;,&quot;pni&quot;,&quot;vmx&quot;,&quot;cx16&quot;,&quot;popcnt&quot;,&quot;hypervisor&quot;,&quot;lahf_lm&quot;],&quot;microcode&quot;:&quot;0x1&quot;}],&quot;Memory&quot;:{&quot;total&quot;:1040777216,&quot;available&quot;:554799104,&quot;used&quot;:485978112,&quot;usedPercent&quot;:46.69376928405013,&quot;free&quot;:53800960,&quot;active&quot;:423022592,&quot;inactive&quot;:442867712,&quot;wired&quot;:0,&quot;buffers&quot;:51183616,&quot;cached&quot;:404344832,&quot;writeback&quot;:0,&quot;dirty&quot;:8192,&quot;writebacktmp&quot;:0,&quot;shared&quot;:10915840,&quot;slab&quot;:87986176,&quot;pagetables&quot;:5287936,&quot;swapcached&quot;:7966720},&quot;GPU&quot;:[]}}
2017-10-12T19:27:09.614Z        INFO    miner/overseer.go:207   subscribe to Docker events      {&quot;since&quot;: &quot;1507836429&quot;}
2017-10-12T19:27:09.622Z        DEBUG   miner/server.go:571     Using hub IP from config        {&quot;IP&quot;: &quot;127.0.0.1:10002&quot;}
2017-10-12T19:27:09.632Z        INFO    miner/server.go:156     handling Handshake request      {&quot;req&quot;: &quot;&quot;}
2017-10-12T19:27:09.639Z        INFO    miner/server.go:415     starting tasks status server
2017-10-12T19:27:09.639Z        DEBUG   miner/server.go:368     handling tasks status request
2017-10-12T19:27:09.639Z        INFO    miner/server.go:343     sending result  {&quot;info&quot;: {}, &quot;statuses&quot;: {}}
2017-10-12T19:27:14.627Z        INFO    miner/server.go:512     yamux.Ping OK   {&quot;rtt&quot;: &quot;201.763µs&quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I assume that one hub supports a cluster of nearby hosts, similar to the master node on Kubernetes.&lt;/p&gt;

&lt;p&gt;Finally, to run a docker container, create a yml file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat &amp;gt; task.yml &amp;lt;&amp;lt;END
&amp;gt; task:
&amp;gt;   container:
&amp;gt;     name: dtandersen/factorio:latest 
&amp;gt;   resources:
&amp;gt;       CPU: 1
&amp;gt;       RAM: 10240kb
&amp;gt;END
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we need to figure out the miner on which to run the task:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./sonmcli --addr 127.0.0.1:10001 miner list
Miner: 127.0.0.1:50928          Idle

$ ./sonmcli --addr 127.0.0.1:10001 miner status 127.0.0.1:50928
Miner: &quot;127.0.0.1:50928&quot; (003fe205-af29-4777-aa2c-a70fd50569ab):
Hardware:
    CPU0: 1 x QEMU Virtual CPU version 1.2.1
    GPU: None
    RAM:
    Total: 992.6 MB
    Used:  463.5 MB
No active tasks
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we can deploy the task:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./sonmcli --addr 127.0.0.1:10001 task start 127.0.0.1:50320 task.yml
Starting &quot;dtandersen/factorio:latest&quot; on miner 127.0.0.1:50928...
ID 94b59103-0c43-4c1e-bc87-9e06abf39ad5
Endpoint [27015/tcp-&amp;gt;207.244.97.166:32772 34197/udp-&amp;gt;207.244.97.166:32769]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This command returns when the task is deployed.&lt;/p&gt;

&lt;p&gt;We inspect the miner again:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ./sonmcli --addr 127.0.0.1:10001 miner status 127.0.0.1:50928
Miner: &quot;127.0.0.1:50928&quot; (003fe205-af29-4777-aa2c-a70fd50569ab):
Hardware:
    CPU0: 1 x QEMU Virtual CPU version 1.2.1
    GPU: None
    RAM:
    Total: 992.6 MB
    Used:  463.5 MB
Tasks:
    1) 94b59103-0c43-4c1e-bc87-9e06abf39ad5
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The entire process took less than 3 minutes in wall clock time.&lt;/p&gt;

&lt;p&gt;Of course, a system this complex will have lots of edge cases. I hope the SONM team have solutions to these pressing issues with fog computing:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Security: user side and miner side&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Proof of execution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dishonest nodes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GPU tasks - SONM will support OpenCL but what about &lt;code class=&quot;highlighter-rouge&quot;&gt;nvidia-docker&lt;/code&gt; required to run TensorFlow?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;SONM marketplace release is scheduled this winter along with a wallet prototype. Here is a diagram of how it works:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/0bb184c987ef6d88ddbd62fde21c596aa4795998/68747470733a2f2f7261772e6769746875622e636f6d2f736f6e6d2d696f2f646f63732f6d61737465722f617263682f73657175656e63652e7376673f73616e6974697a653d74727565&quot; alt=&quot;SONM marketpalce&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I will test these products as they are released.&lt;/p&gt;

</description>
        <pubDate>Thu, 12 Oct 2017 00:37:02 -0400</pubDate>
        <link>http://rickyhan.com/jekyll/update/2017/10/12/running-factorio-headless-on-SONM.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2017/10/12/running-factorio-headless-on-SONM.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Copping Supreme with Haskell</title>
        <description>&lt;p&gt;Recently, a friend asked me to write a program that buys things off of a the shopping site of Supreme website as soon as anything is added. Supreme is a fashion brand that curbs supply to create artificial scarcity, resulting in higher consumer surplus and resell profit margin. So yes, the deadweight loss suffered in the primary market (webstore) is actually paying to incentivize the resellers and increase virality of the brand.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d17ol771963kd3.cloudfront.net/122510/zo/LGlxG_4e95s.jpg&quot; alt=&quot;supreme brick&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This Haskell script does the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;GET website url.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Diff page to determine any changes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If changes are found and within range specified in options, place an order for 100 items.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wait x seconds&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Repeat&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;First, the types:&lt;/p&gt;

&lt;p&gt;```haskell&lt;/p&gt;

&lt;p&gt;type PageHash = String
type PageURL = String
type PageSource = BSL.ByteString&lt;/p&gt;

&lt;p&gt;data Task = Task { pageSource :: PageSource
                 , pageHash :: PageHash
                 } deriving (Show, Eq)&lt;/p&gt;

&lt;p&gt;data TagType = Open
             | Close
             | TextRegex
             deriving (Show, Eq, Ord)&lt;/p&gt;

&lt;p&gt;data Opt = BlackList TagType PageSource
         | WhiteList TagType PageSource
         deriving (Show, Eq, Ord)&lt;/p&gt;

&lt;p&gt;type Opts = [Opt]&lt;/p&gt;

&lt;p&gt;data URL = URL {
  url :: PageURL,
  opts :: Opts
} deriving (Show, Eq, Ord)&lt;/p&gt;

&lt;p&gt;type TaskMap = Map.Map URL Task
```&lt;/p&gt;

&lt;p&gt;The idea is to iterate through a list of &lt;code class=&quot;highlighter-rouge&quot;&gt;URL&lt;/code&gt;s, each with &lt;code class=&quot;highlighter-rouge&quot;&gt;pageSource&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;pageHash&lt;/code&gt;, and then put each URL-Task pair into a Map. In the main loop, compare the old Map to the new Map. If the difference is on &lt;code class=&quot;highlighter-rouge&quot;&gt;WhiteList&lt;/code&gt; and not on &lt;code class=&quot;highlighter-rouge&quot;&gt;BlackList&lt;/code&gt; or fits &lt;code class=&quot;highlighter-rouge&quot;&gt;TextRegex&lt;/code&gt;, then send a notification and place an order for 100 items. The last part may or may not be implemented.&lt;/p&gt;

&lt;p&gt;The implementation is straightforward:&lt;/p&gt;

&lt;p&gt;```haskell
{-# LANGUAGE ViewPatterns #-}&lt;/p&gt;

&lt;p&gt;module Main where&lt;/p&gt;

&lt;p&gt;import Data.IORef (newIORef, readIORef, writeIORef, )
import Control.Monad
import Control.Concurrent (forkIO, threadDelay, )
import qualified Data.Map.Strict as Map&lt;/p&gt;

&lt;p&gt;data GlobalState = GlobalState { tasks :: IORef (Map.Map URL Task) }&lt;/p&gt;

&lt;p&gt;initialize :: IO GlobalState
initialize = do
  titles &amp;lt;- getPages testURLs
  tasksRef &amp;lt;- newIORef titles
  return GlobalState { tasks = tasksRef }&lt;/p&gt;

&lt;p&gt;startTimer :: GlobalState -&amp;gt; IO ()
startTimer (tasks -&amp;gt; ref) = do
  threadId &amp;lt;- forkIO loop
  return ()
  where
    loop = do
      threadDelay $ seconds 1
      oldPages &amp;lt;- readIORef ref
      newPages &amp;lt;- updatePages oldPages
      atomicWriteIORef ref newPages
      print $ getDiffs oldPages newPages
      loop&lt;/p&gt;

&lt;p&gt;seconds :: Num a =&amp;gt; a -&amp;gt; a
seconds = (*) 1000000&lt;/p&gt;

&lt;p&gt;updatePages :: TaskMap -&amp;gt; IO TaskMap
updatePages = getPages . Map.keys&lt;/p&gt;

&lt;p&gt;getPages :: [URL] -&amp;gt; IO TaskMap
getPages urls = do
  tasks &amp;lt;- mapM urlToTask urls
  return $ Map.fromList $ zip urls tasks&lt;/p&gt;

&lt;p&gt;testURLs :: [URL]
testURLs = [
             URL { url = “http://www.supremenewyork.com/shop/jackets/lnmg0t87f/oytwvb5k8”
                 , opts = [
                            BlackList Open “meta”
                          ]
                 }
           ]&lt;/p&gt;

&lt;p&gt;main :: IO ()
main = do
  st &amp;lt;- initialize
  startTimer st
```&lt;/p&gt;

&lt;p&gt;Although functional programming discourages mutable states, sometimes mutable variables are needed. First, &lt;code class=&quot;highlighter-rouge&quot;&gt;getPages&lt;/code&gt; and initialize the task map, and store it in memory using &lt;code class=&quot;highlighter-rouge&quot;&gt;IORef&lt;/code&gt; which operates inside &lt;code class=&quot;highlighter-rouge&quot;&gt;IO&lt;/code&gt; monad to stay perfectly functional. Then in the future, update the reference to the new map.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ViewPatterns&lt;/code&gt; feature flag allows pattern matching on records fields for easy access of data inside (in this case &lt;code class=&quot;highlighter-rouge&quot;&gt;IORef&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Now there are 2 holes yet to be implemented.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;urlToTask&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;Does what it says, &lt;code class=&quot;highlighter-rouge&quot;&gt;URL&lt;/code&gt; in, send requests and hash page source, &lt;code class=&quot;highlighter-rouge&quot;&gt;Task&lt;/code&gt; out.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;getDiffs&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;Checks diffs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;```
import qualified Network.Wreq as Wreq
import Control.Lens
import Data.IORef
import qualified Data.ByteString.Char8 as BS
import qualified Data.ByteString.Lazy as BSL
import qualified Crypto.Hash as H
import qualified Data.Algorithm.Diff
import qualified Data.Map.Strict as Map
import qualified Text.HTML.TagSoup as TS&lt;/p&gt;

&lt;p&gt;fetchPage :: String -&amp;gt; IO (Maybe PageSource)
fetchPage url = do
  r &amp;lt;- Wreq.get url
  return $ r ^? Wreq.responseBody&lt;/p&gt;

&lt;p&gt;hexSha3_512 :: BS.ByteString -&amp;gt; PageHash
hexSha3_512 bs = show (H.hash bs :: H.Digest H.SHA1)&lt;/p&gt;

&lt;p&gt;pageToHash :: BSL.ByteString -&amp;gt; PageHash
pageToHash page = do
  let strictBS = BSL.toStrict page
  hexSha3_512 strictBS&lt;/p&gt;

&lt;p&gt;urlToTask :: URL -&amp;gt; IO Task
urlToTask URL {url=url, opts=opts}= do
  pageSource &amp;lt;- fetchPage url
  case pageSource of
    Just source -&amp;gt; return Task { pageSource = source
    	                       , pageHash = pageToHash source
    	                       , pageOpts = opts
    	                       }
```&lt;/p&gt;

&lt;p&gt;Nothing to see here. Wreq is the HTTP library whose results can be accessed using Lens. Hash &lt;code class=&quot;highlighter-rouge&quot;&gt;responseBody&lt;/code&gt; for later use and store source, hash, and opts in &lt;code class=&quot;highlighter-rouge&quot;&gt;Task&lt;/code&gt; record.&lt;/p&gt;

&lt;p&gt;Here is the implementation for the &lt;code class=&quot;highlighter-rouge&quot;&gt;getDiff&lt;/code&gt; method(in a separate module).&lt;/p&gt;

&lt;p&gt;```haskell
{-# LANGUAGE OverloadedStrings #-}&lt;/p&gt;

&lt;p&gt;module Diff where&lt;/p&gt;

&lt;p&gt;import Lib
import Control.Monad
import qualified Data.Algorithm.Diff as D
import qualified Data.Algorithm.DiffOutput as D
import qualified Data.Map.Strict as Map
import qualified Text.HTML.TagSoup as TS
import Debug.Trace
import Text.Regex.PCRE&lt;/p&gt;

&lt;p&gt;getDiffs :: TaskMap -&amp;gt; TaskMap -&amp;gt; Map.Map URL (Maybe Bool)
getDiffs olds news = Map.mapWithKey diff olds
  where
    diff key oldTask = do
      newTask &amp;lt;- Map.lookup key news&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  let hash  = pageHash oldTask
  let hash&#39; = pageHash newTask

  let diffs = D.getDiff (parsedSource oldTask) (parsedSource newTask)
  let options = opts key
  let filteredDiffs = filtered options diffs

  let changed = (hash /= hash&#39;) &amp;amp;&amp;amp; (not.null $ filteredDiffs)
  if changed
    then traceM $ ppDiff filteredDiffs
    else traceM &quot;Nothing changed&quot;
  return changed
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;parsedSource :: Task -&amp;gt; [TS.Tag PageSource]
parsedSource = TS.parseTags . pageSource&lt;/p&gt;

&lt;p&gt;ppDiff :: [D.Diff (TS.Tag PageSource)] -&amp;gt; String
ppDiff = unlines . ppDiffPairs&lt;/p&gt;

&lt;p&gt;ppDiffPairs :: [D.Diff (TS.Tag PageSource)] -&amp;gt; [String]
ppDiffPairs diffs = zipWith
      ((D.First first) (D.Second second) -&amp;gt;
         “«««\n”
      ++ show first
      ++ “\n======\n”
      ++ show second
      ++ “\n»»»\n”
      )
    (onlyFirsts diffs) (onlySeconds diffs)&lt;/p&gt;

&lt;p&gt;onlySeconds :: [D.Diff t] -&amp;gt; [D.Diff t]
onlySeconds = filter (\diff -&amp;gt;
  case diff of
    D.Second _ -&amp;gt; True
    _         -&amp;gt; False)&lt;/p&gt;

&lt;p&gt;onlyFirsts :: [D.Diff t] -&amp;gt; [D.Diff t]
onlyFirsts = filter (\diff -&amp;gt;
  case diff of
    D.First _ -&amp;gt; True
    _         -&amp;gt; False)&lt;/p&gt;

&lt;p&gt;filtered :: Opts -&amp;gt; [D.Diff (TS.Tag PageSource)] -&amp;gt; [D.Diff (TS.Tag PageSource)]
filtered options diffs = filter(\diff -&amp;gt; all (\option -&amp;gt; ok option diff) options ) diffs
  where ok option diff = case diff of D.Both _ _ -&amp;gt; False
                                      _          -&amp;gt; case option of BlackList Open name -&amp;gt; not $ TS.isTagOpenName name d
                                                                   BlackList Close name -&amp;gt; not $ TS.isTagCloseName name d
                                                                   BlackList TextRegex regex -&amp;gt; TS.isTagText d &amp;amp;&amp;amp; (TS.fromTagText d =~ regex)
                                                                   WhiteList Open name -&amp;gt; name == “*” || TS.isTagOpenName name d
                                                                   _ -&amp;gt; undefined
                                                                   where d = fromDiff diff&lt;/p&gt;

&lt;p&gt;fromDiff :: D.Diff (TS.Tag PageSource) -&amp;gt; TS.Tag PageSource
fromDiff (D.First a) = a
fromDiff (D.Second a) = a
```&lt;/p&gt;

&lt;p&gt;Most of the logic is in &lt;code class=&quot;highlighter-rouge&quot;&gt;getDiffs&lt;/code&gt;: first compare the new hash with the old hash. If &lt;code class=&quot;highlighter-rouge&quot;&gt;pageSource&lt;/code&gt; changed, then find the difference of the pages at the level of HTML tags. To do this, &lt;code class=&quot;highlighter-rouge&quot;&gt;TagSoup&lt;/code&gt; is used to parse &lt;code class=&quot;highlighter-rouge&quot;&gt;pageSource&lt;/code&gt; into a list of &lt;code class=&quot;highlighter-rouge&quot;&gt;Tag&lt;/code&gt;s. Since &lt;code class=&quot;highlighter-rouge&quot;&gt;Tag&lt;/code&gt; implements &lt;code class=&quot;highlighter-rouge&quot;&gt;Eq&lt;/code&gt; typeclass, it is supported by the diff algorithm. This is where the typeclass system really becomes useful.&lt;/p&gt;

&lt;p&gt;Now that the diffs are calculated, just need to filter out the ones that we said we wanted in options. Since options are implemented on the type level as opposed to data level, pattern matching against types is necessary. &lt;code class=&quot;highlighter-rouge&quot;&gt;Options&lt;/code&gt; is a product type which is pleasant to pattern match against.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Using Haskell, we can monitor pages in a modular and type safe manner.&lt;/p&gt;

&lt;p&gt;After reading about Supreme drops online, I realized the website only changes on Thursdays so I won’t know what urls to watch.&lt;/p&gt;

&lt;p&gt;Later, I lost interest in fashion and this project is abandoned.&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Sep 2017 00:37:02 -0400</pubDate>
        <link>http://rickyhan.com/jekyll/update/2017/09/27/copping-supreme-with-haskell.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2017/09/27/copping-supreme-with-haskell.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Gradient Trader Part 2: Visualizing Bitcoin Order Book</title>
        <description>&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Update: Nov. 17 2017:&lt;/strong&gt; All algorithms on this page have been &lt;a href=&quot;https://github.com/rickyhan/tectonicdb/tree/master/src/lib&quot;&gt;ported to Rust&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this short post I will demonstrate how to use the order book. I am giving out  visualization algorithms for free.&lt;/p&gt;

&lt;p&gt;Visualization should lead to truth and understanding. There are different ways of visualizing the order book. We will start with the simplest one.&lt;/p&gt;

&lt;p&gt;This is the supply-demand curve.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.stack.imgur.com/UBUfx.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Order book on Bittrex:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tonyy.in/content/images/2017/08/Screen-Shot-2017-08-08-at-9.42.13-PM.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see in the simplest case, the order book is nothing but the transpose of the supply-demand curve zoomed in. This is a simple visualization - most traders can only catch a fleeting glimpse. Its utility is limited to spotting walls at any instant.&lt;/p&gt;

&lt;p&gt;Now let’s work our way up towards better visualization.&lt;/p&gt;

&lt;h1 id=&quot;establish-db-connection&quot;&gt;Establish DB Connection&lt;/h1&gt;

&lt;p&gt;First, establish a connection to the database and retrieve orderbook updates over 1 hour.&lt;/p&gt;

&lt;p&gt;The following is a trick to “proxy/forward” a db connection using ssh. Let’s say the database(&lt;code class=&quot;highlighter-rouge&quot;&gt;dburl&lt;/code&gt;) is configured to only accept connections from &lt;code class=&quot;highlighter-rouge&quot;&gt;secure-server&lt;/code&gt;, then it’s used to simply forward the port from &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;dburl&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ssh rhan@secure-server -CNL localhost:5432:dburl:5432&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```python
import psycopg2
import sys
from time import time
from pprint import pprint
import matplotlib.pyplot as plt
import numpy as np
from math import floor, ceil
import datetime
import pandas as pd
from matplotlib.colors import LinearSegmentedColormap
import copy&lt;/p&gt;

&lt;p&gt;conn_string = “host=’localhost’ dbname=’bittrex’ user=’rhan’ password=’[REDACTED]’”
conn = psycopg2.connect(conn_string)
cursor = conn.cursor()
```&lt;/p&gt;

&lt;h1 id=&quot;configure-matplotlib&quot;&gt;Configure &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt;&lt;/h1&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
plt.rcParams[&quot;font.family&quot;] = &quot;Ubuntu Mono&quot;
plt.grid(False)
plt.axis(&#39;on&#39;)
plt.style.use(&#39;dark_background&#39;)
&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&quot;retrieve-data&quot;&gt;Retrieve Data&lt;/h1&gt;

&lt;p&gt;We only need the following columns:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ts&lt;/code&gt;:
Timestamp of the order received by client.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;seq&lt;/code&gt;:
Sequence number to re-order the events received.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;size&lt;/code&gt;:
Order size&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;price&lt;/code&gt;:
Price of order&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;is_bid&lt;/code&gt;:
Is the order a buy or sell&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;is_trade&lt;/code&gt;:
Is it a market order or limit order&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Although the exchange may send other fields such as trade id, update type(create, delete, partial fill) and some exchange-specific order types, the above is the minimum set of fields to reconstruct an order book.&lt;/p&gt;

&lt;p&gt;```python
h = int(time()) # ! do not change
h_ago = h - 7200&lt;/p&gt;

&lt;p&gt;cursor.execute(“””
    SELECT ts, seq, size, price, is_bid, is_trade
      FROM orderbook_btc_neo
     WHERE ts &amp;gt; {} AND ts &amp;lt; {}
  ORDER BY seq ASC;
“”“.format(h_ago, h))
result = cursor.fetchall()
conn.commit()
```&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
print (result[-1][0] - result[0][0]) / 60, &quot;minutes&quot;
&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;119.984233332 minutes
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
events = pd.DataFrame.from_records(result,
                                       columns=[&quot;ts&quot;, &quot;seq&quot;, &quot;size&quot;, &quot;price&quot;, &quot;is_bid&quot;, &quot;is_trade&quot;],
                                       index=&quot;seq&quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Now let us plot price distributions&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
prices = np.array(events[&quot;price&quot;])
plt.hist(prices)
plt.title(&quot;Price distribution&quot;)
plt.show()
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_10_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see, most of the liquidity aggregates in 1 bin. So let’s “zoom in” on this bin.&lt;/p&gt;

&lt;p&gt;```python
def reject_outliers(data, m = 2.):
    d = np.abs(data - np.median(data))
    mdev = np.median(d)
    s = d/mdev if mdev else 0.
    return data[s&amp;lt;m]&lt;/p&gt;

&lt;p&gt;rejected = reject_outliers(prices, m=4)
plt.hist(rejected)
plt.title(“Outliers rejected”)
plt.show()
```&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_12_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Internally, &lt;code class=&quot;highlighter-rouge&quot;&gt;plt.hist&lt;/code&gt; uses &lt;code class=&quot;highlighter-rouge&quot;&gt;np.histogram&lt;/code&gt; which we will later use to get a list of boundaries to rebin the ticks.&lt;/p&gt;

&lt;p&gt;Also trivial is the percentage of buy/sell market orders. These orders are considered “aggressive” as in crossing the spread. The plot below is not weighted by order size.&lt;/p&gt;

&lt;p&gt;```python
is_bids = events[events[“is_trade”]][“is_bid”]
total_events_cnt = is_bids.size
bids = np.sum(is_bids)
asks = total_events_cnt - bids&lt;/p&gt;

&lt;p&gt;plt.pie([bids, asks])
plt.legend([“bids”, “asks”])
plt.title(“bid/ask”)
plt.show()
```&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_14_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;split-events-into-separate-categories&quot;&gt;Split Events into Separate Categories&lt;/h1&gt;

&lt;p&gt;We split events into three categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;limit order creation&lt;/li&gt;
  &lt;li&gt;limit order cancellation&lt;/li&gt;
  &lt;li&gt;market order&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is done by comparing the previous liquidity &lt;script type=&quot;math/tex&quot;&gt;s_{t-1}&lt;/script&gt; to the new liquidity &lt;script type=&quot;math/tex&quot;&gt;s_{t}&lt;/script&gt; at a given price level &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;```python
cols = [“ts”, “seq”, “size”, “price”, “is_bid”, “is_trade”]&lt;/p&gt;

&lt;p&gt;cancelled = []
created = []
current_level = {}&lt;/p&gt;

&lt;p&gt;for seq, (ts, size, price, is_bid, is_trade) in events.sort_index().iterrows():
    if not is_trade:
        prev = current_level[price] if price in current_level else 0
        if (size == 0 or size &amp;lt;= prev):
            cancelled.append((ts, seq, prev - size, price, is_bid, is_trade))
        elif (size &amp;gt; prev):
            created.append((ts, seq, size - prev, price, is_bid, is_trade))
        else: # size == prev
            raise Exception(“Impossible”)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;current_level[price] = size
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;cancelled = pd.DataFrame.from_records(cancelled, columns=cols, index=”seq”)
created =   pd.DataFrame.from_records(created,   columns=cols, index=”seq”)
trades = events[events[‘is_trade’]]&lt;/p&gt;

&lt;h1 id=&quot;sanity-check&quot;&gt;sanity check&lt;/h1&gt;
&lt;p&gt;assert len(cancelled) + len(created) + len(trades) == len(events)
```&lt;/p&gt;

&lt;h1 id=&quot;visualize-individual-orders&quot;&gt;Visualize Individual Orders&lt;/h1&gt;

&lt;p&gt;Visualizing order cancellation/creation is the lowest level one can go about visualization. The x-axis is time, y-axis is size of order. It provides insights into the activities of individual market participants.&lt;/p&gt;

&lt;p&gt;```python
import datetime as dt
import matplotlib.dates as md&lt;/p&gt;

&lt;p&gt;def plotVolumeMap(df, volFrom=None, volTo=None, log_scale=True):
    if volFrom:
        df = df[df[“size”] &amp;gt;= volFrom]
    if volTo:
        df = df[df[“size”] &amp;lt;= volTo]&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;colors = map(lambda b: &#39;#ffff00&#39; if b else &#39;#00ffff&#39;, df[&quot;is_bid&quot;])

fig = plt.figure(figsize=(24, 18))
ax = fig.add_subplot(111)
if log_scale:
    ax.set_yscale(&#39;log&#39;)

plt.scatter(df[&quot;ts&quot;], df[&quot;size&quot;], c=colors, s=5)
plt.legend([&quot;bid&quot;])
plt.show() ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
plotVolumeMap(cancelled, volFrom=100, volTo=200, log_scale=True)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_19_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
plotVolumeMap(cancelled, volFrom=1, volTo=30, log_scale=True)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_20_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By filtering out events within a volume range, it is possible to isolate what are most likely individual order placement strategies.&lt;/p&gt;

&lt;p&gt;I don’t understand how this bot works. If you do please let me know.&lt;/p&gt;

&lt;h1 id=&quot;rebinning-events&quot;&gt;Rebinning Events&lt;/h1&gt;

&lt;p&gt;Now we convert events into deltas that have a start time and end time. In the process, rebin the events along the time and ticks axis so more liquidity aggregates on each tick.&lt;/p&gt;

&lt;p&gt;This way, we can plot how the order book evolves over time.&lt;/p&gt;

&lt;p&gt;```python
def to_updates(events):
    tick_bins_cnt = 2000
    step_bins_cnt = 2000&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sizes, boundaries = np.histogram(rejected, tick_bins_cnt)
def into_tick_bin(price):
    for (s, b) in zip(boundaries, boundaries[1:]):
        if b &amp;gt; price &amp;gt; s:
            return s
    return False

min_ts = result[0][0]
max_ts = result[-1][0]
step_thresholds = range(int(floor(min_ts)), int(ceil(max_ts)), int(floor((max_ts - min_ts)/(step_bins_cnt))))
def into_step_bin(time):
    for (s, b) in zip(step_thresholds, step_thresholds[1:]):
        if b &amp;gt; time &amp;gt; s:
            return b
    return False
    
updates = {}
for row in result:
    ts, seq, size, price, is_bid, is_trade = row
    price = into_tick_bin(price)
    time = into_step_bin(ts)
    if not price or not time:
        continue
    if price not in updates:
        updates[price] = {}
    if time not in updates[price]:
        updates[price][time] = 0
    updates[price][time] += size;
return updates ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
updates = to_updates(events) # expensive
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```python
def plot_price_levels(updates, zorder=0, max_threshold=100, min_threshold=0.5):  &lt;br /&gt;
    ys = []
    xmins = []
    xmaxs = []
    colors = []&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for price, vdict in updates.items():
    vtuples = vdict.items()
    vtuples = sorted(vtuples, key=lambda tup: tup[0])
    for (t1, s1), (t2, s2) in zip(vtuples, vtuples[1:]): # bigram
        xmins.append(t1)
        xmaxs.append(t2)
        ys.append(price)
        if s1 &amp;lt; min_threshold:
            colors.append((0, 0, 0))
        elif s1 &amp;gt; max_threshold:
            colors.append((0, 1, 1))
        else:
            colors.append((0, s1/max_threshold, s1/max_threshold))
plt.hlines(ys, xmins, xmaxs, color=colors, lw=3, alpha=1, zorder=zorder) #     plt.colorbar()     ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
plt.figure(figsize=(24, 18))
plot_price_levels(updates, max_threshold=100, min_threshold=10)
plt.show()
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_26_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This visualization technique is from the famous &lt;a href=&quot;http://www.nanex.net/aqck2/4586.html&quot;&gt;Nanex Research&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;An interesting strategy emerges using this visualization:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Q5vdjs0.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note the orders sitting far from the market are pegged to be x basis points from the inside.&lt;/p&gt;

&lt;h1 id=&quot;reconstructing-order-book&quot;&gt;Reconstructing Order Book&lt;/h1&gt;

&lt;p&gt;We can also reconstruct order book to get order book depth at each instant. With the shape of the order book at each time step, we can plot how the best bid and ask change over time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://lobsterdata.com/images/figures/HowDoesItWork_ReconstructionAlgorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The algorithm is very straightforward. Order book updates are tracked by keeping a temp copy of the limit order book and store each updated “temp” version into a dictionary indexed by timestamps.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
def get_ob():
    most_recent_orderbook = {&quot;bids&quot;: {}, &quot;asks&quot;: {}}
    orderbook = {}
    for seq, e in events.iterrows():
        if e.is_trade:
            continue
        if e.ts not in orderbook:
            for side, sidedicts in most_recent_orderbook.items():
                for price, size in sidedicts.items():
                    if size == 0:
                        del sidedicts[price]
            most_recent_orderbook[&quot;bids&quot; if e.is_bid else &quot;asks&quot;][e.price] = e[&quot;size&quot;]
            orderbook[e.ts] = copy.deepcopy(most_recent_orderbook)        
    return orderbook
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```python
def best_ba(orderbook):
    best_bids_asks = []&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for ts, ob in orderbook.items():
    try:
        best_bid = max(ob[&quot;bids&quot;].keys())
    except: # sometimes L in max(L) is []
        continue
    try:
        best_ask = min(ob[&quot;asks&quot;].keys())
    except:
        continue
    best_bids_asks.append((ts, best_bid, best_ask))

best_bids_asks = pd.DataFrame.from_records(best_bids_asks, columns=[&quot;ts&quot;, &quot;best_bid&quot;, &quot;best_ask&quot;], index=&quot;ts&quot;).sort_index()
return best_bids_asks ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;```python
def plot_best_ba(best_ba_df):
    bhys = []    # bid - horizontal - ys
    bhxmins = [] # bid - horizontal - xmins
    bhxmaxs = [] # …
    bvxs = []
    bvymins = []
    bvymaxs = []
    ahys = []
    ahxmins = []
    ahxmaxs = []
    avxs = []
    avymins = []
    avymaxs = []&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bba_tuple = best_ba_df.to_records()
for (ts1, b1, a1), (ts2, b2, a2) in zip(bba_tuple, bba_tuple[1:]): # bigram
    bhys.append(b1)
    bhxmins.append(ts1)
    bhxmaxs.append(ts2)
    bvxs.append(ts2)
    bvymins.append(b1)
    bvymaxs.append(b2)
    ahys.append(a1)
    ahxmins.append(ts1)
    ahxmaxs.append(ts2)
    avxs.append(ts2)
    avymins.append(a1)
    avymaxs.append(a2)

plt.hlines(bhys, bhxmins, bhxmaxs, color=&quot;green&quot;, lw=3, alpha=1)
plt.vlines(bvxs, bvymins, bvymaxs, color=&quot;green&quot;, lw=3, alpha=1)
plt.hlines(ahys, ahxmins, ahxmaxs, color=&quot;red&quot;, lw=3, alpha=1)
plt.vlines(avxs, avymins, avymaxs, color=&quot;red&quot;, lw=3, alpha=1) ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
def plot_trades(trades, size=1, zorder=10):
    trades_colors = map(lambda is_bid: &quot;#00ff00&quot; if is_bid else &quot;#ff0000&quot;, trades.is_bid)
    plt.scatter(trades[&quot;ts&quot;], trades[&quot;price&quot;], s=trades[&quot;size&quot;]*size, color=trades_colors, zorder=zorder)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
ob = get_ob() # expensive
best_ba_df = best_ba(ob) # expensive
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```python
plt.figure(figsize=(24, 18))&lt;/p&gt;

&lt;p&gt;plot_best_ba(best_ba_df)
plot_trades(trades, size=0.5, zorder=10)
plot_price_levels(updates, zorder=0, max_threshold=60, min_threshold=1)
plt.ylim([0.00529, 0.005425])&lt;/p&gt;

&lt;p&gt;plt.show()
```&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_34_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;```python
def plot_events(df, trades_df=None, min_price=None, max_price=None, log_scale=True):
    if min_price:
        df = df[(df[“price”] &amp;gt; min_price)]
        if trades_df is not None:
            trades_df = trades_df[(trades_df[“price”] &amp;gt; min_price)]
    if max_price:
        df =  df[(df[“price”] &amp;lt; max_price)]
        if trades_df is not None:
            trades_df =  trades_df[(trades_df[“price”] &amp;lt; max_price)]&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fig = plt.figure(figsize=(24, 18))
ax = fig.add_subplot(111)

if trades_df is not None:
    plt.title(&quot;Trades And Cancellation&quot;)
    plt.legend([&quot;Trades&quot;, &quot;Cancellation&quot;])
    plt.scatter(trades_df[&quot;ts&quot;], trades_df[&quot;price&quot;], s=trades_df[&quot;size&quot;], color=&quot;#00ffff&quot;)
    plt.scatter(df[&quot;ts&quot;], df[&quot;price&quot;], s=df[&quot;size&quot;]/30, color=&quot;#ffff00&quot;)
else:
    plt.scatter(df[&quot;ts&quot;], df[&quot;price&quot;], s=df[&quot;size&quot;], color=&quot;#ffff00&quot;)
    plt.legend(&quot;Cancelled&quot;)
    plt.title(&quot;Cancellation&quot;)
if log_scale:
    ax.set_yscale(&#39;log&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;plot_events(cancelled, trades_df=trades, min_price=0.00499, max_price=0.00529, log_scale=False)
plt.show()
```&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_35_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;```python
def plot_ob(bidask, bps=.25):
    # bps: basis points&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;best_bid = max(bidask[&quot;bids&quot;].keys())
best_ask = min(bidask[&quot;asks&quot;].keys())
worst_bid = best_bid * (1 - bps)
worst_ask = best_bid * (1 + bps)
filtered_bids = sorted(filter(lambda (k,v): k &amp;gt;= worst_bid, bidask[&#39;bids&#39;].items()), key=lambda x:-x[0])
filtered_asks = sorted(filter(lambda (k,v): k &amp;lt;= worst_ask, bidask[&#39;asks&#39;].items()), key=lambda x:+x[0])

bsizeacc = 0
bhys = []    # bid - horizontal - ys
bhxmins = [] # bid - horizontal - xmins
bhxmaxs = [] # ...
bvxs = []
bvymins = []
bvymaxs = []
asizeacc = 0
ahys = []
ahxmins = []
ahxmaxs = []
avxs = []
avymins = []
avymaxs = []

for (p1, s1), (p2, s2) in zip(filtered_bids, filtered_bids[1:]):
    bvymins.append(bsizeacc)
    if bsizeacc == 0:
        bsizeacc += s1
    bhys.append(bsizeacc)
    bhxmins.append(p2)
    bhxmaxs.append(p1)
    bvxs.append(p2)
    bsizeacc += s2
    bvymaxs.append(bsizeacc)

for (p1, s1), (p2, s2) in zip(filtered_asks, filtered_asks[1:]):
    avymins.append(asizeacc)
    if asizeacc == 0:
        asizeacc += s1
    ahys.append(asizeacc)
    ahxmins.append(p1)
    ahxmaxs.append(p2)
    avxs.append(p2)
    asizeacc += s2
    avymaxs.append(asizeacc)
    
plt.hlines(bhys, bhxmins, bhxmaxs, color=&quot;green&quot;)
plt.vlines(bvxs, bvymins, bvymaxs, color=&quot;green&quot;)
plt.hlines(ahys, ahxmins, ahxmaxs, color=&quot;red&quot;)
plt.vlines(avxs, avymins, avymaxs, color=&quot;red&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;dts--maxobkeys&quot;&gt;d_ts = max(ob.keys())&lt;/h1&gt;
&lt;p&gt;# d_ob = ob[d_ts]
plt.figure(figsize=(10,4))
plot_ob(d_ob, bps=.05)
plt.ylim([0, 17500])
plt.show()
```&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/viz/output_36_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python
cursor.close()
conn.close()
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is a demonstration of some visualization algorithms using &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt;. As you can see, they are fairly straightforward to implement.&lt;/p&gt;

&lt;p&gt;In the future I plan on porting such visualization to &lt;a href=&quot;https://github.com/rrag/react-stockcharts&quot;&gt;react-stockcharts&lt;/a&gt; so I can interactively explore data. The algorithms are already here, what is left to be done is changing matplotlib calls to d3. If you would like to collaborate with me on this, please email me.&lt;/p&gt;
</description>
        <pubDate>Sun, 24 Sep 2017 00:37:02 -0400</pubDate>
        <link>http://rickyhan.com/jekyll/update/2017/09/24/visualizing-order-book.html</link>
        <guid isPermaLink="true">http://rickyhan.com/jekyll/update/2017/09/24/visualizing-order-book.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
  </channel>
</rss>
